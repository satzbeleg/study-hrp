22-11-06 08:14:29 - INFO - sentence_transformers.SentenceTransformer: Load pretrained SentenceTransformer: distiluse-base-multilingual-cased-v2
22-11-06 08:14:30 - INFO - sentence_transformers.SentenceTransformer: Use pytorch device: cuda
22-11-06 08:14:30 - INFO - __main__: SBert model distiluse-base-multilingual-cased-v2 is loaded.
22-11-06 08:14:32 - INFO - __main__: Num of SBert features: 512
22-11-06 08:14:32 - INFO - root: Generating sentence embeddings
22-11-06 08:14:36 - INFO - root: Generated sentence embeddings
22-11-06 08:14:36 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation
22-11-06 08:15:09 - INFO - root: Best param found at split 1: l2reg = 0.0001                 with score 75.67
22-11-06 08:15:42 - INFO - root: Best param found at split 2: l2reg = 0.0001                 with score 75.0
22-11-06 08:16:13 - INFO - root: Best param found at split 3: l2reg = 1e-05                 with score 75.84
22-11-06 08:16:42 - INFO - root: Best param found at split 4: l2reg = 1e-05                 with score 75.08
22-11-06 08:17:11 - INFO - root: Best param found at split 5: l2reg = 0.0001                 with score 75.46
22-11-06 08:17:12 - INFO - root: Generating sentence embeddings
22-11-06 08:17:14 - INFO - root: Generated sentence embeddings
22-11-06 08:17:14 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation
22-11-06 08:17:23 - INFO - root: Best param found at split 1: l2reg = 0.0001                 with score 83.94
22-11-06 08:17:34 - INFO - root: Best param found at split 2: l2reg = 0.0001                 with score 83.48
22-11-06 08:17:45 - INFO - root: Best param found at split 3: l2reg = 1e-05                 with score 84.01
22-11-06 08:17:56 - INFO - root: Best param found at split 4: l2reg = 1e-05                 with score 83.38
22-11-06 08:18:07 - INFO - root: Best param found at split 5: l2reg = 0.0001                 with score 83.01
22-11-06 08:18:08 - INFO - root: Generating sentence embeddings
22-11-06 08:18:12 - INFO - root: Generated sentence embeddings
22-11-06 08:18:12 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation
22-11-06 08:18:38 - INFO - root: Best param found at split 1: l2reg = 0.0001                 with score 92.16
22-11-06 08:19:09 - INFO - root: Best param found at split 2: l2reg = 1e-05                 with score 92.56
22-11-06 08:19:36 - INFO - root: Best param found at split 3: l2reg = 1e-05                 with score 92.29
22-11-06 08:20:09 - INFO - root: Best param found at split 4: l2reg = 1e-05                 with score 92.44
22-11-06 08:20:37 - INFO - root: Best param found at split 5: l2reg = 1e-05                 with score 92.06
22-11-06 08:20:39 - INFO - root: Generating sentence embeddings
22-11-06 08:20:41 - INFO - root: Generated sentence embeddings
22-11-06 08:20:41 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation
22-11-06 08:21:09 - INFO - root: Best param found at split 1: l2reg = 1e-05                 with score 87.99
22-11-06 08:21:39 - INFO - root: Best param found at split 2: l2reg = 0.0001                 with score 87.31
22-11-06 08:22:07 - INFO - root: Best param found at split 3: l2reg = 1e-05                 with score 87.71
22-11-06 08:22:36 - INFO - root: Best param found at split 4: l2reg = 1e-05                 with score 87.37
22-11-06 08:23:05 - INFO - root: Best param found at split 5: l2reg = 1e-05                 with score 87.33
22-11-06 08:23:07 - INFO - root: Computing embedding for train
22-11-06 08:23:10 - INFO - root: Computed train embeddings
22-11-06 08:23:10 - INFO - root: Computing embedding for dev
22-11-06 08:23:10 - INFO - root: Computed dev embeddings
22-11-06 08:23:10 - INFO - root: Computing embedding for test
22-11-06 08:23:11 - INFO - root: Computed test embeddings
22-11-06 08:23:11 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with standard validation..
22-11-06 08:23:18 - INFO - root: [('reg:1e-05', 43.78), ('reg:0.0001', 43.51), ('reg:0.001', 42.33), ('reg:0.01', 36.97)]
22-11-06 08:23:18 - INFO - root: Validation : best param found is reg = 1e-05 with score             43.78
22-11-06 08:23:18 - INFO - root: Evaluating...
22-11-06 08:23:21 - INFO - root: ***** Transfer task : TREC *****


22-11-06 08:23:22 - INFO - root: Computed train embeddings
22-11-06 08:23:22 - INFO - root: Computed test embeddings
22-11-06 08:23:22 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with 5-fold cross-validation
22-11-06 08:23:45 - INFO - root: [('reg:1e-05', 89.34), ('reg:0.0001', 89.18), ('reg:0.001', 86.78), ('reg:0.01', 80.14)]
22-11-06 08:23:45 - INFO - root: Cross-validation : best param found is reg = 1e-05             with score 89.34
22-11-06 08:23:45 - INFO - root: Evaluating...
22-11-06 08:23:46 - INFO - root: ***** Transfer task : MRPC *****


22-11-06 08:23:46 - INFO - root: Computing embedding for train
22-11-06 08:23:49 - INFO - root: Computed train embeddings
22-11-06 08:23:49 - INFO - root: Computing embedding for test
22-11-06 08:23:51 - INFO - root: Computed test embeddings
22-11-06 08:23:51 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with 5-fold cross-validation
22-11-06 08:24:04 - INFO - root: [('reg:1e-05', 75.81), ('reg:0.0001', 75.88), ('reg:0.001', 75.44), ('reg:0.01', 73.87)]
22-11-06 08:24:04 - INFO - root: Cross-validation : best param found is reg = 0.0001             with score 75.88
22-11-06 08:24:04 - INFO - root: Evaluating...
22-11-18 20:32:50 - INFO - sentence_transformers.SentenceTransformer: Load pretrained SentenceTransformer: distiluse-base-multilingual-cased-v2
22-11-18 20:32:51 - INFO - sentence_transformers.SentenceTransformer: Use pytorch device: cuda
22-11-18 20:32:51 - INFO - __main__: SBert model distiluse-base-multilingual-cased-v2 is loaded.
22-11-18 20:32:53 - INFO - __main__: Num of SBert features: 512
