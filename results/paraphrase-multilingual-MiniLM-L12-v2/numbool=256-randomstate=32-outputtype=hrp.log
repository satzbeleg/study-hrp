22-11-05 04:25:09 - INFO - sentence_transformers.SentenceTransformer: Load pretrained SentenceTransformer: paraphrase-multilingual-MiniLM-L12-v2
22-11-05 04:25:11 - INFO - sentence_transformers.SentenceTransformer: Use pytorch device: cuda
22-11-05 04:25:11 - INFO - __main__: SBert model paraphrase-multilingual-MiniLM-L12-v2 is loaded.
22-11-05 04:25:13 - INFO - __main__: Num of SBert features: 384
22-11-05 04:25:14 - INFO - root: Generating sentence embeddings
22-11-05 04:25:18 - INFO - root: Generated sentence embeddings
22-11-05 04:25:18 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation
22-11-05 04:25:47 - INFO - root: Best param found at split 1: l2reg = 0.01                 with score 75.81
22-11-05 04:26:14 - INFO - root: Best param found at split 2: l2reg = 0.01                 with score 74.6
22-11-05 04:26:42 - INFO - root: Best param found at split 3: l2reg = 1e-05                 with score 75.29
22-11-05 04:27:12 - INFO - root: Best param found at split 4: l2reg = 0.001                 with score 75.4
22-11-05 04:27:43 - INFO - root: Best param found at split 5: l2reg = 1e-05                 with score 75.77
22-11-05 04:27:44 - INFO - root: Generating sentence embeddings
22-11-05 04:27:46 - INFO - root: Generated sentence embeddings
22-11-05 04:27:46 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation
22-11-05 04:27:55 - INFO - root: Best param found at split 1: l2reg = 0.01                 with score 87.38
22-11-05 04:28:06 - INFO - root: Best param found at split 2: l2reg = 0.0001                 with score 87.32
22-11-05 04:28:15 - INFO - root: Best param found at split 3: l2reg = 1e-05                 with score 86.92
22-11-05 04:28:25 - INFO - root: Best param found at split 4: l2reg = 0.01                 with score 86.99
22-11-05 04:28:35 - INFO - root: Best param found at split 5: l2reg = 1e-05                 with score 86.46
22-11-05 04:28:35 - INFO - root: Generating sentence embeddings
22-11-05 04:28:39 - INFO - root: Generated sentence embeddings
22-11-05 04:28:39 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation
22-11-05 04:29:04 - INFO - root: Best param found at split 1: l2reg = 0.01                 with score 89.06
22-11-05 04:29:31 - INFO - root: Best param found at split 2: l2reg = 0.001                 with score 89.51
22-11-05 04:29:55 - INFO - root: Best param found at split 3: l2reg = 0.01                 with score 89.09
22-11-05 04:30:22 - INFO - root: Best param found at split 4: l2reg = 1e-05                 with score 88.78
22-11-05 04:30:50 - INFO - root: Best param found at split 5: l2reg = 0.001                 with score 89.04
22-11-05 04:30:51 - INFO - root: Generating sentence embeddings
22-11-05 04:30:55 - INFO - root: Generated sentence embeddings
22-11-05 04:30:55 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation
22-11-05 04:31:21 - INFO - root: Best param found at split 1: l2reg = 0.01                 with score 87.54
22-11-05 04:31:51 - INFO - root: Best param found at split 2: l2reg = 0.001                 with score 86.71
22-11-05 04:32:10 - INFO - root: Best param found at split 3: l2reg = 0.001                 with score 87.53
22-11-05 04:32:31 - INFO - root: Best param found at split 4: l2reg = 0.01                 with score 87.53
22-11-05 04:33:00 - INFO - root: Best param found at split 5: l2reg = 0.01                 with score 86.56
22-11-05 04:33:02 - INFO - root: Computing embedding for train
22-11-05 04:33:05 - INFO - root: Computed train embeddings
22-11-05 04:33:05 - INFO - root: Computing embedding for dev
22-11-05 04:33:05 - INFO - root: Computed dev embeddings
22-11-05 04:33:05 - INFO - root: Computing embedding for test
22-11-05 04:33:06 - INFO - root: Computed test embeddings
22-11-05 04:33:06 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with standard validation..
22-11-05 04:33:12 - INFO - root: [('reg:1e-05', 40.69), ('reg:0.0001', 40.78), ('reg:0.001', 40.6), ('reg:0.01', 39.24)]
22-11-05 04:33:12 - INFO - root: Validation : best param found is reg = 0.0001 with score             40.78
22-11-05 04:33:12 - INFO - root: Evaluating...
22-11-05 04:33:14 - INFO - root: ***** Transfer task : TREC *****


22-11-05 04:33:16 - INFO - root: Computed train embeddings
22-11-05 04:33:16 - INFO - root: Computed test embeddings
22-11-05 04:33:16 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with 5-fold cross-validation
22-11-05 04:33:36 - INFO - root: [('reg:1e-05', 69.77), ('reg:0.0001', 69.81), ('reg:0.001', 69.61), ('reg:0.01', 66.23)]
22-11-05 04:33:36 - INFO - root: Cross-validation : best param found is reg = 0.0001             with score 69.81
22-11-05 04:33:36 - INFO - root: Evaluating...
22-11-05 04:33:37 - INFO - root: ***** Transfer task : MRPC *****


22-11-05 04:33:37 - INFO - root: Computing embedding for train
22-11-05 04:33:40 - INFO - root: Computed train embeddings
22-11-05 04:33:40 - INFO - root: Computing embedding for test
22-11-05 04:33:42 - INFO - root: Computed test embeddings
22-11-05 04:33:42 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with 5-fold cross-validation
22-11-05 04:33:55 - INFO - root: [('reg:1e-05', 72.28), ('reg:0.0001', 72.94), ('reg:0.001', 73.01), ('reg:0.01', 72.99)]
22-11-05 04:33:55 - INFO - root: Cross-validation : best param found is reg = 0.001             with score 73.01
22-11-05 04:33:55 - INFO - root: Evaluating...
22-11-18 09:58:34 - INFO - sentence_transformers.SentenceTransformer: Load pretrained SentenceTransformer: paraphrase-multilingual-MiniLM-L12-v2
22-11-18 09:58:36 - INFO - sentence_transformers.SentenceTransformer: Use pytorch device: cuda
22-11-18 09:58:36 - INFO - __main__: SBert model paraphrase-multilingual-MiniLM-L12-v2 is loaded.
22-11-18 09:58:37 - INFO - __main__: Num of SBert features: 384
