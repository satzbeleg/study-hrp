22-11-05 05:45:15 - INFO - sentence_transformers.SentenceTransformer: Load pretrained SentenceTransformer: paraphrase-multilingual-MiniLM-L12-v2
22-11-05 05:45:16 - INFO - sentence_transformers.SentenceTransformer: Use pytorch device: cuda
22-11-05 05:45:16 - INFO - __main__: SBert model paraphrase-multilingual-MiniLM-L12-v2 is loaded.
22-11-05 05:45:18 - INFO - __main__: Num of SBert features: 384
22-11-05 05:45:19 - INFO - root: Generating sentence embeddings
22-11-05 05:45:23 - INFO - root: Generated sentence embeddings
22-11-05 05:45:23 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation
22-11-05 05:45:51 - INFO - root: Best param found at split 1: l2reg = 0.01                 with score 76.91
22-11-05 05:46:17 - INFO - root: Best param found at split 2: l2reg = 0.001                 with score 76.03
22-11-05 05:46:46 - INFO - root: Best param found at split 3: l2reg = 0.001                 with score 75.56
22-11-05 05:47:13 - INFO - root: Best param found at split 4: l2reg = 1e-05                 with score 75.74
22-11-05 05:47:45 - INFO - root: Best param found at split 5: l2reg = 0.001                 with score 76.1
22-11-05 05:47:47 - INFO - root: Generating sentence embeddings
22-11-05 05:47:49 - INFO - root: Generated sentence embeddings
22-11-05 05:47:49 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation
22-11-05 05:47:57 - INFO - root: Best param found at split 1: l2reg = 1e-05                 with score 86.66
22-11-05 05:48:06 - INFO - root: Best param found at split 2: l2reg = 0.01                 with score 87.52
22-11-05 05:48:17 - INFO - root: Best param found at split 3: l2reg = 0.01                 with score 87.42
22-11-05 05:48:26 - INFO - root: Best param found at split 4: l2reg = 1e-05                 with score 87.81
22-11-05 05:48:36 - INFO - root: Best param found at split 5: l2reg = 0.0001                 with score 87.19
22-11-05 05:48:36 - INFO - root: Generating sentence embeddings
22-11-05 05:48:41 - INFO - root: Generated sentence embeddings
22-11-05 05:48:41 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation
22-11-05 05:49:06 - INFO - root: Best param found at split 1: l2reg = 0.001                 with score 89.75
22-11-05 05:49:33 - INFO - root: Best param found at split 2: l2reg = 0.01                 with score 90.09
22-11-05 05:49:58 - INFO - root: Best param found at split 3: l2reg = 0.001                 with score 89.56
22-11-05 05:50:22 - INFO - root: Best param found at split 4: l2reg = 0.01                 with score 89.18
22-11-05 05:50:48 - INFO - root: Best param found at split 5: l2reg = 0.01                 with score 89.56
22-11-05 05:50:50 - INFO - root: Generating sentence embeddings
22-11-05 05:50:54 - INFO - root: Generated sentence embeddings
22-11-05 05:50:54 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation
22-11-05 05:51:17 - INFO - root: Best param found at split 1: l2reg = 1e-05                 with score 86.82
22-11-05 05:51:47 - INFO - root: Best param found at split 2: l2reg = 0.01                 with score 87.99
22-11-05 05:52:12 - INFO - root: Best param found at split 3: l2reg = 0.01                 with score 87.58
22-11-05 05:52:38 - INFO - root: Best param found at split 4: l2reg = 0.001                 with score 87.92
22-11-05 05:53:00 - INFO - root: Best param found at split 5: l2reg = 0.01                 with score 87.71
22-11-05 05:53:01 - INFO - root: Computing embedding for train
22-11-05 05:53:05 - INFO - root: Computed train embeddings
22-11-05 05:53:05 - INFO - root: Computing embedding for dev
22-11-05 05:53:05 - INFO - root: Computed dev embeddings
22-11-05 05:53:05 - INFO - root: Computing embedding for test
22-11-05 05:53:06 - INFO - root: Computed test embeddings
22-11-05 05:53:06 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with standard validation..
22-11-05 05:53:13 - INFO - root: [('reg:1e-05', 42.69), ('reg:0.0001', 42.78), ('reg:0.001', 42.51), ('reg:0.01', 42.23)]
22-11-05 05:53:13 - INFO - root: Validation : best param found is reg = 0.0001 with score             42.78
22-11-05 05:53:13 - INFO - root: Evaluating...
22-11-05 05:53:15 - INFO - root: ***** Transfer task : TREC *****


22-11-05 05:53:17 - INFO - root: Computed train embeddings
22-11-05 05:53:17 - INFO - root: Computed test embeddings
22-11-05 05:53:17 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with 5-fold cross-validation
22-11-05 05:53:36 - INFO - root: [('reg:1e-05', 71.77), ('reg:0.0001', 71.75), ('reg:0.001', 71.72), ('reg:0.01', 68.97)]
22-11-05 05:53:36 - INFO - root: Cross-validation : best param found is reg = 1e-05             with score 71.77
22-11-05 05:53:36 - INFO - root: Evaluating...
22-11-05 05:53:37 - INFO - root: ***** Transfer task : MRPC *****


22-11-05 05:53:37 - INFO - root: Computing embedding for train
22-11-05 05:53:40 - INFO - root: Computed train embeddings
22-11-05 05:53:40 - INFO - root: Computing embedding for test
22-11-05 05:53:42 - INFO - root: Computed test embeddings
22-11-05 05:53:42 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with 5-fold cross-validation
22-11-05 05:53:55 - INFO - root: [('reg:1e-05', 72.42), ('reg:0.0001', 72.64), ('reg:0.001', 72.25), ('reg:0.01', 72.74)]
22-11-05 05:53:55 - INFO - root: Cross-validation : best param found is reg = 0.01             with score 72.74
22-11-05 05:53:55 - INFO - root: Evaluating...
22-11-18 10:27:41 - INFO - sentence_transformers.SentenceTransformer: Load pretrained SentenceTransformer: paraphrase-multilingual-MiniLM-L12-v2
22-11-18 10:27:42 - INFO - sentence_transformers.SentenceTransformer: Use pytorch device: cuda
22-11-18 10:27:42 - INFO - __main__: SBert model paraphrase-multilingual-MiniLM-L12-v2 is loaded.
22-11-18 10:27:44 - INFO - __main__: Num of SBert features: 384
