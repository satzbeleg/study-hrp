22-11-05 13:17:24 - INFO - sentence_transformers.SentenceTransformer: Load pretrained SentenceTransformer: paraphrase-multilingual-MiniLM-L12-v2
22-11-05 13:17:25 - INFO - sentence_transformers.SentenceTransformer: Use pytorch device: cuda
22-11-05 13:17:25 - INFO - __main__: SBert model paraphrase-multilingual-MiniLM-L12-v2 is loaded.
22-11-05 13:17:27 - INFO - __main__: Num of SBert features: 384
22-11-05 13:17:28 - INFO - root: Generating sentence embeddings
22-11-05 13:17:32 - INFO - root: Generated sentence embeddings
22-11-05 13:17:32 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation
22-11-05 13:17:58 - INFO - root: Best param found at split 1: l2reg = 0.01                 with score 77.44
22-11-05 13:18:27 - INFO - root: Best param found at split 2: l2reg = 0.01                 with score 76.97
22-11-05 13:18:57 - INFO - root: Best param found at split 3: l2reg = 0.0001                 with score 76.71
22-11-05 13:19:25 - INFO - root: Best param found at split 4: l2reg = 0.01                 with score 76.07
22-11-05 13:19:56 - INFO - root: Best param found at split 5: l2reg = 1e-05                 with score 76.25
22-11-05 13:19:57 - INFO - root: Generating sentence embeddings
22-11-05 13:19:59 - INFO - root: Generated sentence embeddings
22-11-05 13:19:59 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation
22-11-05 13:20:08 - INFO - root: Best param found at split 1: l2reg = 1e-05                 with score 87.62
22-11-05 13:20:19 - INFO - root: Best param found at split 2: l2reg = 0.0001                 with score 87.55
22-11-05 13:20:29 - INFO - root: Best param found at split 3: l2reg = 0.01                 with score 87.12
22-11-05 13:20:38 - INFO - root: Best param found at split 4: l2reg = 0.01                 with score 87.22
22-11-05 13:20:48 - INFO - root: Best param found at split 5: l2reg = 0.01                 with score 87.09
22-11-05 13:20:48 - INFO - root: Generating sentence embeddings
22-11-05 13:20:53 - INFO - root: Generated sentence embeddings
22-11-05 13:20:53 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation
22-11-05 13:21:17 - INFO - root: Best param found at split 1: l2reg = 0.001                 with score 90.15
22-11-05 13:21:43 - INFO - root: Best param found at split 2: l2reg = 0.01                 with score 90.7
22-11-05 13:22:09 - INFO - root: Best param found at split 3: l2reg = 0.001                 with score 90.71
22-11-05 13:22:32 - INFO - root: Best param found at split 4: l2reg = 0.001                 with score 90.06
22-11-05 13:22:59 - INFO - root: Best param found at split 5: l2reg = 1e-05                 with score 90.19
22-11-05 13:23:00 - INFO - root: Generating sentence embeddings
22-11-05 13:23:04 - INFO - root: Generated sentence embeddings
22-11-05 13:23:04 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation
22-11-05 13:23:30 - INFO - root: Best param found at split 1: l2reg = 0.0001                 with score 87.69
22-11-05 13:23:58 - INFO - root: Best param found at split 2: l2reg = 0.0001                 with score 87.51
22-11-05 13:24:25 - INFO - root: Best param found at split 3: l2reg = 0.001                 with score 88.13
22-11-05 13:24:54 - INFO - root: Best param found at split 4: l2reg = 0.0001                 with score 87.46
22-11-05 13:25:20 - INFO - root: Best param found at split 5: l2reg = 0.01                 with score 85.52
22-11-05 13:25:21 - INFO - root: Computing embedding for train
22-11-05 13:25:25 - INFO - root: Computed train embeddings
22-11-05 13:25:25 - INFO - root: Computing embedding for dev
22-11-05 13:25:25 - INFO - root: Computed dev embeddings
22-11-05 13:25:25 - INFO - root: Computing embedding for test
22-11-05 13:25:26 - INFO - root: Computed test embeddings
22-11-05 13:25:26 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with standard validation..
22-11-05 13:25:30 - INFO - root: [('reg:1e-05', 39.24), ('reg:0.0001', 38.51), ('reg:0.001', 40.78), ('reg:0.01', 41.78)]
22-11-05 13:25:30 - INFO - root: Validation : best param found is reg = 0.01 with score             41.78
22-11-05 13:25:30 - INFO - root: Evaluating...
22-11-05 13:25:31 - INFO - root: ***** Transfer task : TREC *****


22-11-05 13:25:33 - INFO - root: Computed train embeddings
22-11-05 13:25:33 - INFO - root: Computed test embeddings
22-11-05 13:25:33 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with 5-fold cross-validation
22-11-05 13:25:51 - INFO - root: [('reg:1e-05', 71.61), ('reg:0.0001', 71.72), ('reg:0.001', 72.32), ('reg:0.01', 70.01)]
22-11-05 13:25:51 - INFO - root: Cross-validation : best param found is reg = 0.001             with score 72.32
22-11-05 13:25:51 - INFO - root: Evaluating...
22-11-05 13:25:52 - INFO - root: ***** Transfer task : MRPC *****


22-11-05 13:25:52 - INFO - root: Computing embedding for train
22-11-05 13:25:56 - INFO - root: Computed train embeddings
22-11-05 13:25:56 - INFO - root: Computing embedding for test
22-11-05 13:25:57 - INFO - root: Computed test embeddings
22-11-05 13:25:57 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with 5-fold cross-validation
22-11-05 13:26:09 - INFO - root: [('reg:1e-05', 73.18), ('reg:0.0001', 72.79), ('reg:0.001', 72.99), ('reg:0.01', 72.87)]
22-11-05 13:26:09 - INFO - root: Cross-validation : best param found is reg = 1e-05             with score 73.18
22-11-05 13:26:09 - INFO - root: Evaluating...
22-11-18 13:18:40 - INFO - sentence_transformers.SentenceTransformer: Load pretrained SentenceTransformer: paraphrase-multilingual-MiniLM-L12-v2
22-11-18 13:18:42 - INFO - sentence_transformers.SentenceTransformer: Use pytorch device: cuda
22-11-18 13:18:42 - INFO - __main__: SBert model paraphrase-multilingual-MiniLM-L12-v2 is loaded.
22-11-18 13:18:44 - INFO - __main__: Num of SBert features: 384
