22-11-05 15:31:14 - INFO - sentence_transformers.SentenceTransformer: Load pretrained SentenceTransformer: paraphrase-multilingual-MiniLM-L12-v2
22-11-05 15:31:15 - INFO - sentence_transformers.SentenceTransformer: Use pytorch device: cuda
22-11-05 15:31:15 - INFO - __main__: SBert model paraphrase-multilingual-MiniLM-L12-v2 is loaded.
22-11-05 15:31:18 - INFO - __main__: Num of SBert features: 384
22-11-05 15:31:19 - INFO - root: Generating sentence embeddings
22-11-05 15:31:23 - INFO - root: Generated sentence embeddings
22-11-05 15:31:23 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation
22-11-05 15:31:54 - INFO - root: Best param found at split 1: l2reg = 1e-05                 with score 78.18
22-11-05 15:32:22 - INFO - root: Best param found at split 2: l2reg = 0.01                 with score 77.98
22-11-05 15:32:51 - INFO - root: Best param found at split 3: l2reg = 0.01                 with score 76.67
22-11-05 15:33:22 - INFO - root: Best param found at split 4: l2reg = 0.01                 with score 77.44
22-11-05 15:33:52 - INFO - root: Best param found at split 5: l2reg = 0.01                 with score 76.83
22-11-05 15:33:53 - INFO - root: Generating sentence embeddings
22-11-05 15:33:55 - INFO - root: Generated sentence embeddings
22-11-05 15:33:55 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation
22-11-05 15:34:04 - INFO - root: Best param found at split 1: l2reg = 0.001                 with score 87.98
22-11-05 15:34:14 - INFO - root: Best param found at split 2: l2reg = 0.001                 with score 88.61
22-11-05 15:34:24 - INFO - root: Best param found at split 3: l2reg = 0.01                 with score 88.05
22-11-05 15:34:35 - INFO - root: Best param found at split 4: l2reg = 0.01                 with score 88.34
22-11-05 15:34:45 - INFO - root: Best param found at split 5: l2reg = 1e-05                 with score 87.38
22-11-05 15:34:45 - INFO - root: Generating sentence embeddings
22-11-05 15:34:49 - INFO - root: Generated sentence embeddings
22-11-05 15:34:49 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation
22-11-05 15:35:11 - INFO - root: Best param found at split 1: l2reg = 0.01                 with score 90.84
22-11-05 15:35:35 - INFO - root: Best param found at split 2: l2reg = 0.01                 with score 91.29
22-11-05 15:36:02 - INFO - root: Best param found at split 3: l2reg = 0.01                 with score 91.2
22-11-05 15:36:27 - INFO - root: Best param found at split 4: l2reg = 0.0001                 with score 90.82
22-11-05 15:36:53 - INFO - root: Best param found at split 5: l2reg = 0.01                 with score 91.04
22-11-05 15:36:54 - INFO - root: Generating sentence embeddings
22-11-05 15:36:58 - INFO - root: Generated sentence embeddings
22-11-05 15:36:58 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation
22-11-05 15:37:24 - INFO - root: Best param found at split 1: l2reg = 0.01                 with score 88.55
22-11-05 15:37:54 - INFO - root: Best param found at split 2: l2reg = 0.001                 with score 88.06
22-11-05 15:38:24 - INFO - root: Best param found at split 3: l2reg = 0.001                 with score 88.67
22-11-05 15:38:51 - INFO - root: Best param found at split 4: l2reg = 0.0001                 with score 88.26
22-11-05 15:39:15 - INFO - root: Best param found at split 5: l2reg = 0.0001                 with score 88.11
22-11-05 15:39:16 - INFO - root: Computing embedding for train
22-11-05 15:39:20 - INFO - root: Computed train embeddings
22-11-05 15:39:20 - INFO - root: Computing embedding for dev
22-11-05 15:39:20 - INFO - root: Computed dev embeddings
22-11-05 15:39:20 - INFO - root: Computing embedding for test
22-11-05 15:39:21 - INFO - root: Computed test embeddings
22-11-05 15:39:21 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with standard validation..
22-11-05 15:39:28 - INFO - root: [('reg:1e-05', 39.6), ('reg:0.0001', 36.88), ('reg:0.001', 38.96), ('reg:0.01', 41.05)]
22-11-05 15:39:28 - INFO - root: Validation : best param found is reg = 0.01 with score             41.05
22-11-05 15:39:28 - INFO - root: Evaluating...
22-11-05 15:39:30 - INFO - root: ***** Transfer task : TREC *****


22-11-05 15:39:32 - INFO - root: Computed train embeddings
22-11-05 15:39:32 - INFO - root: Computed test embeddings
22-11-05 15:39:32 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with 5-fold cross-validation
22-11-05 15:39:50 - INFO - root: [('reg:1e-05', 74.08), ('reg:0.0001', 73.62), ('reg:0.001', 72.83), ('reg:0.01', 69.88)]
22-11-05 15:39:50 - INFO - root: Cross-validation : best param found is reg = 1e-05             with score 74.08
22-11-05 15:39:50 - INFO - root: Evaluating...
22-11-05 15:39:51 - INFO - root: ***** Transfer task : MRPC *****


22-11-05 15:39:51 - INFO - root: Computing embedding for train
22-11-05 15:39:54 - INFO - root: Computed train embeddings
22-11-05 15:39:54 - INFO - root: Computing embedding for test
22-11-05 15:39:56 - INFO - root: Computed test embeddings
22-11-05 15:39:56 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with 5-fold cross-validation
22-11-05 15:40:09 - INFO - root: [('reg:1e-05', 72.84), ('reg:0.0001', 72.74), ('reg:0.001', 73.11), ('reg:0.01', 72.74)]
22-11-05 15:40:09 - INFO - root: Cross-validation : best param found is reg = 0.001             with score 73.11
22-11-05 15:40:09 - INFO - root: Evaluating...
22-11-18 14:11:03 - INFO - sentence_transformers.SentenceTransformer: Load pretrained SentenceTransformer: paraphrase-multilingual-MiniLM-L12-v2
22-11-18 14:11:05 - INFO - sentence_transformers.SentenceTransformer: Use pytorch device: cuda
22-11-18 14:11:05 - INFO - __main__: SBert model paraphrase-multilingual-MiniLM-L12-v2 is loaded.
22-11-18 14:11:06 - INFO - __main__: Num of SBert features: 384
