22-11-05 02:40:02 - INFO - sentence_transformers.SentenceTransformer: Load pretrained SentenceTransformer: paraphrase-multilingual-MiniLM-L12-v2
22-11-05 02:40:03 - INFO - sentence_transformers.SentenceTransformer: Use pytorch device: cuda
22-11-05 02:40:03 - INFO - __main__: SBert model paraphrase-multilingual-MiniLM-L12-v2 is loaded.
22-11-05 02:40:06 - INFO - __main__: Num of SBert features: 384
22-11-05 02:40:07 - INFO - root: Generating sentence embeddings
22-11-05 02:40:11 - INFO - root: Generated sentence embeddings
22-11-05 02:40:11 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation
22-11-05 02:40:41 - INFO - root: Best param found at split 1: l2reg = 0.01                 with score 76.23
22-11-05 02:41:11 - INFO - root: Best param found at split 2: l2reg = 0.0001                 with score 75.55
22-11-05 02:41:43 - INFO - root: Best param found at split 3: l2reg = 0.0001                 with score 75.63
22-11-05 02:42:14 - INFO - root: Best param found at split 4: l2reg = 0.001                 with score 75.73
22-11-05 02:42:44 - INFO - root: Best param found at split 5: l2reg = 0.01                 with score 75.84
22-11-05 02:42:46 - INFO - root: Generating sentence embeddings
22-11-05 02:42:47 - INFO - root: Generated sentence embeddings
22-11-05 02:42:47 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation
22-11-05 02:42:56 - INFO - root: Best param found at split 1: l2reg = 0.001                 with score 86.26
22-11-05 02:43:06 - INFO - root: Best param found at split 2: l2reg = 0.001                 with score 86.46
22-11-05 02:43:16 - INFO - root: Best param found at split 3: l2reg = 1e-05                 with score 86.16
22-11-05 02:43:26 - INFO - root: Best param found at split 4: l2reg = 0.001                 with score 86.19
22-11-05 02:43:36 - INFO - root: Best param found at split 5: l2reg = 1e-05                 with score 86.03
22-11-05 02:43:36 - INFO - root: Generating sentence embeddings
22-11-05 02:43:40 - INFO - root: Generated sentence embeddings
22-11-05 02:43:40 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation
22-11-05 02:44:05 - INFO - root: Best param found at split 1: l2reg = 1e-05                 with score 87.87
22-11-05 02:44:30 - INFO - root: Best param found at split 2: l2reg = 1e-05                 with score 88.14
22-11-05 02:44:59 - INFO - root: Best param found at split 3: l2reg = 0.0001                 with score 88.2
22-11-05 02:45:23 - INFO - root: Best param found at split 4: l2reg = 0.001                 with score 87.52
22-11-05 02:45:50 - INFO - root: Best param found at split 5: l2reg = 0.001                 with score 88.05
22-11-05 02:45:52 - INFO - root: Generating sentence embeddings
22-11-05 02:45:56 - INFO - root: Generated sentence embeddings
22-11-05 02:45:56 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation
22-11-05 02:46:21 - INFO - root: Best param found at split 1: l2reg = 1e-05                 with score 84.45
22-11-05 02:46:49 - INFO - root: Best param found at split 2: l2reg = 0.01                 with score 85.72
22-11-05 02:47:17 - INFO - root: Best param found at split 3: l2reg = 1e-05                 with score 85.36
22-11-05 02:47:45 - INFO - root: Best param found at split 4: l2reg = 0.01                 with score 86.61
22-11-05 02:48:10 - INFO - root: Best param found at split 5: l2reg = 0.01                 with score 86.46
22-11-05 02:48:11 - INFO - root: Computing embedding for train
22-11-05 02:48:15 - INFO - root: Computed train embeddings
22-11-05 02:48:15 - INFO - root: Computing embedding for dev
22-11-05 02:48:15 - INFO - root: Computed dev embeddings
22-11-05 02:48:15 - INFO - root: Computing embedding for test
22-11-05 02:48:16 - INFO - root: Computed test embeddings
22-11-05 02:48:16 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with standard validation..
22-11-05 02:48:23 - INFO - root: [('reg:1e-05', 41.24), ('reg:0.0001', 41.24), ('reg:0.001', 40.51), ('reg:0.01', 40.15)]
22-11-05 02:48:23 - INFO - root: Validation : best param found is reg = 1e-05 with score             41.24
22-11-05 02:48:23 - INFO - root: Evaluating...
22-11-05 02:48:25 - INFO - root: ***** Transfer task : TREC *****


22-11-05 02:48:27 - INFO - root: Computed train embeddings
22-11-05 02:48:27 - INFO - root: Computed test embeddings
22-11-05 02:48:27 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with 5-fold cross-validation
22-11-05 02:48:42 - INFO - root: [('reg:1e-05', 67.26), ('reg:0.0001', 67.33), ('reg:0.001', 67.08), ('reg:0.01', 66.18)]
22-11-05 02:48:42 - INFO - root: Cross-validation : best param found is reg = 0.0001             with score 67.33
22-11-05 02:48:42 - INFO - root: Evaluating...
22-11-05 02:48:44 - INFO - root: ***** Transfer task : MRPC *****


22-11-05 02:48:44 - INFO - root: Computing embedding for train
22-11-05 02:48:47 - INFO - root: Computed train embeddings
22-11-05 02:48:47 - INFO - root: Computing embedding for test
22-11-05 02:48:49 - INFO - root: Computed test embeddings
22-11-05 02:48:49 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with 5-fold cross-validation
22-11-05 02:49:03 - INFO - root: [('reg:1e-05', 72.1), ('reg:0.0001', 72.06), ('reg:0.001', 72.01), ('reg:0.01', 72.67)]
22-11-05 02:49:03 - INFO - root: Cross-validation : best param found is reg = 0.01             with score 72.67
22-11-05 02:49:03 - INFO - root: Evaluating...
22-11-18 09:20:34 - INFO - sentence_transformers.SentenceTransformer: Load pretrained SentenceTransformer: paraphrase-multilingual-MiniLM-L12-v2
22-11-18 09:20:36 - INFO - sentence_transformers.SentenceTransformer: Use pytorch device: cuda
22-11-18 09:20:36 - INFO - __main__: SBert model paraphrase-multilingual-MiniLM-L12-v2 is loaded.
22-11-18 09:20:38 - INFO - __main__: Num of SBert features: 384
