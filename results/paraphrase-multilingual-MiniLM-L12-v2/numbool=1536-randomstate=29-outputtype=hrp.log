22-11-06 01:34:27 - INFO - sentence_transformers.SentenceTransformer: Load pretrained SentenceTransformer: paraphrase-multilingual-MiniLM-L12-v2
22-11-06 01:34:29 - INFO - sentence_transformers.SentenceTransformer: Use pytorch device: cuda
22-11-06 01:34:29 - INFO - __main__: SBert model paraphrase-multilingual-MiniLM-L12-v2 is loaded.
22-11-06 01:34:31 - INFO - __main__: Num of SBert features: 384
22-11-06 01:34:31 - INFO - root: Generating sentence embeddings
22-11-06 01:34:36 - INFO - root: Generated sentence embeddings
22-11-06 01:34:36 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation
22-11-06 01:35:05 - INFO - root: Best param found at split 1: l2reg = 0.0001                 with score 78.31
22-11-06 01:35:30 - INFO - root: Best param found at split 2: l2reg = 1e-05                 with score 77.22
22-11-06 01:36:00 - INFO - root: Best param found at split 3: l2reg = 0.01                 with score 79.18
22-11-06 01:36:28 - INFO - root: Best param found at split 4: l2reg = 0.001                 with score 78.28
22-11-06 01:36:49 - INFO - root: Best param found at split 5: l2reg = 0.0001                 with score 76.49
22-11-06 01:36:49 - INFO - root: Generating sentence embeddings
22-11-06 01:36:51 - INFO - root: Generated sentence embeddings
22-11-06 01:36:51 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation
22-11-06 01:36:59 - INFO - root: Best param found at split 1: l2reg = 0.0001                 with score 88.28
22-11-06 01:37:09 - INFO - root: Best param found at split 2: l2reg = 0.001                 with score 88.87
22-11-06 01:37:18 - INFO - root: Best param found at split 3: l2reg = 0.01                 with score 88.38
22-11-06 01:37:27 - INFO - root: Best param found at split 4: l2reg = 0.01                 with score 88.38
22-11-06 01:37:37 - INFO - root: Best param found at split 5: l2reg = 0.01                 with score 88.15
22-11-06 01:37:37 - INFO - root: Generating sentence embeddings
22-11-06 01:37:42 - INFO - root: Generated sentence embeddings
22-11-06 01:37:42 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation
22-11-06 01:38:07 - INFO - root: Best param found at split 1: l2reg = 0.01                 with score 91.2
22-11-06 01:38:33 - INFO - root: Best param found at split 2: l2reg = 0.001                 with score 91.86
22-11-06 01:38:49 - INFO - root: Best param found at split 3: l2reg = 0.0001                 with score 91.28
22-11-06 01:39:16 - INFO - root: Best param found at split 4: l2reg = 1e-05                 with score 91.11
22-11-06 01:39:43 - INFO - root: Best param found at split 5: l2reg = 0.01                 with score 91.11
22-11-06 01:39:45 - INFO - root: Generating sentence embeddings
22-11-06 01:39:48 - INFO - root: Generated sentence embeddings
22-11-06 01:39:48 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation
22-11-06 01:40:19 - INFO - root: Best param found at split 1: l2reg = 0.01                 with score 89.29
22-11-06 01:40:48 - INFO - root: Best param found at split 2: l2reg = 0.0001                 with score 88.43
22-11-06 01:41:16 - INFO - root: Best param found at split 3: l2reg = 0.01                 with score 89.23
22-11-06 01:41:45 - INFO - root: Best param found at split 4: l2reg = 0.01                 with score 88.84
22-11-06 01:42:14 - INFO - root: Best param found at split 5: l2reg = 0.01                 with score 89.0
22-11-06 01:42:15 - INFO - root: Computing embedding for train
22-11-06 01:42:19 - INFO - root: Computed train embeddings
22-11-06 01:42:19 - INFO - root: Computing embedding for dev
22-11-06 01:42:19 - INFO - root: Computed dev embeddings
22-11-06 01:42:19 - INFO - root: Computing embedding for test
22-11-06 01:42:20 - INFO - root: Computed test embeddings
22-11-06 01:42:20 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with standard validation..
22-11-06 01:42:27 - INFO - root: [('reg:1e-05', 42.42), ('reg:0.0001', 37.51), ('reg:0.001', 38.78), ('reg:0.01', 43.69)]
22-11-06 01:42:27 - INFO - root: Validation : best param found is reg = 0.01 with score             43.69
22-11-06 01:42:27 - INFO - root: Evaluating...
22-11-06 01:42:29 - INFO - root: ***** Transfer task : TREC *****


22-11-06 01:42:31 - INFO - root: Computed train embeddings
22-11-06 01:42:31 - INFO - root: Computed test embeddings
22-11-06 01:42:31 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with 5-fold cross-validation
22-11-06 01:42:51 - INFO - root: [('reg:1e-05', 73.39), ('reg:0.0001', 76.78), ('reg:0.001', 73.81), ('reg:0.01', 71.95)]
22-11-06 01:42:51 - INFO - root: Cross-validation : best param found is reg = 0.0001             with score 76.78
22-11-06 01:42:51 - INFO - root: Evaluating...
22-11-06 01:42:52 - INFO - root: ***** Transfer task : MRPC *****


22-11-06 01:42:52 - INFO - root: Computing embedding for train
22-11-06 01:42:56 - INFO - root: Computed train embeddings
22-11-06 01:42:56 - INFO - root: Computing embedding for test
22-11-06 01:42:57 - INFO - root: Computed test embeddings
22-11-06 01:42:57 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with 5-fold cross-validation
22-11-06 01:43:11 - INFO - root: [('reg:1e-05', 74.07), ('reg:0.0001', 71.91), ('reg:0.001', 73.06), ('reg:0.01', 73.55)]
22-11-06 01:43:11 - INFO - root: Cross-validation : best param found is reg = 1e-05             with score 74.07
22-11-06 01:43:11 - INFO - root: Evaluating...
22-11-18 17:56:54 - INFO - sentence_transformers.SentenceTransformer: Load pretrained SentenceTransformer: paraphrase-multilingual-MiniLM-L12-v2
22-11-18 17:56:56 - INFO - sentence_transformers.SentenceTransformer: Use pytorch device: cuda
22-11-18 17:56:56 - INFO - __main__: SBert model paraphrase-multilingual-MiniLM-L12-v2 is loaded.
22-11-18 17:56:57 - INFO - __main__: Num of SBert features: 384
