22-11-05 16:25:17 - INFO - sentence_transformers.SentenceTransformer: Load pretrained SentenceTransformer: paraphrase-multilingual-MiniLM-L12-v2
22-11-05 16:25:18 - INFO - sentence_transformers.SentenceTransformer: Use pytorch device: cuda
22-11-05 16:25:18 - INFO - __main__: SBert model paraphrase-multilingual-MiniLM-L12-v2 is loaded.
22-11-05 16:25:20 - INFO - __main__: Num of SBert features: 384
22-11-05 16:25:21 - INFO - root: Generating sentence embeddings
22-11-05 16:25:26 - INFO - root: Generated sentence embeddings
22-11-05 16:25:26 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation
22-11-05 16:25:54 - INFO - root: Best param found at split 1: l2reg = 0.01                 with score 77.76
22-11-05 16:26:19 - INFO - root: Best param found at split 2: l2reg = 0.001                 with score 78.02
22-11-05 16:26:50 - INFO - root: Best param found at split 3: l2reg = 0.001                 with score 77.83
22-11-05 16:27:19 - INFO - root: Best param found at split 4: l2reg = 1e-05                 with score 77.49
22-11-05 16:27:48 - INFO - root: Best param found at split 5: l2reg = 1e-05                 with score 77.12
22-11-05 16:27:49 - INFO - root: Generating sentence embeddings
22-11-05 16:27:51 - INFO - root: Generated sentence embeddings
22-11-05 16:27:51 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation
22-11-05 16:28:00 - INFO - root: Best param found at split 1: l2reg = 0.0001                 with score 87.25
22-11-05 16:28:10 - INFO - root: Best param found at split 2: l2reg = 0.001                 with score 88.41
22-11-05 16:28:21 - INFO - root: Best param found at split 3: l2reg = 0.01                 with score 87.58
22-11-05 16:28:30 - INFO - root: Best param found at split 4: l2reg = 1e-05                 with score 87.81
22-11-05 16:28:40 - INFO - root: Best param found at split 5: l2reg = 0.001                 with score 87.45
22-11-05 16:28:40 - INFO - root: Generating sentence embeddings
22-11-05 16:28:45 - INFO - root: Generated sentence embeddings
22-11-05 16:28:45 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation
22-11-05 16:29:10 - INFO - root: Best param found at split 1: l2reg = 0.01                 with score 90.69
22-11-05 16:29:36 - INFO - root: Best param found at split 2: l2reg = 0.01                 with score 91.11
22-11-05 16:30:03 - INFO - root: Best param found at split 3: l2reg = 0.01                 with score 90.58
22-11-05 16:30:30 - INFO - root: Best param found at split 4: l2reg = 0.0001                 with score 90.36
22-11-05 16:30:56 - INFO - root: Best param found at split 5: l2reg = 0.01                 with score 90.71
22-11-05 16:30:58 - INFO - root: Generating sentence embeddings
22-11-05 16:31:01 - INFO - root: Generated sentence embeddings
22-11-05 16:31:01 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation
22-11-05 16:31:28 - INFO - root: Best param found at split 1: l2reg = 1e-05                 with score 88.58
22-11-05 16:31:57 - INFO - root: Best param found at split 2: l2reg = 0.0001                 with score 87.68
22-11-05 16:32:27 - INFO - root: Best param found at split 3: l2reg = 0.01                 with score 88.44
22-11-05 16:32:52 - INFO - root: Best param found at split 4: l2reg = 0.001                 with score 88.45
22-11-05 16:33:17 - INFO - root: Best param found at split 5: l2reg = 0.01                 with score 87.92
22-11-05 16:33:19 - INFO - root: Computing embedding for train
22-11-05 16:33:22 - INFO - root: Computed train embeddings
22-11-05 16:33:22 - INFO - root: Computing embedding for dev
22-11-05 16:33:23 - INFO - root: Computed dev embeddings
22-11-05 16:33:23 - INFO - root: Computing embedding for test
22-11-05 16:33:24 - INFO - root: Computed test embeddings
22-11-05 16:33:24 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with standard validation..
22-11-05 16:33:32 - INFO - root: [('reg:1e-05', 41.69), ('reg:0.0001', 38.24), ('reg:0.001', 40.78), ('reg:0.01', 38.15)]
22-11-05 16:33:32 - INFO - root: Validation : best param found is reg = 1e-05 with score             41.69
22-11-05 16:33:32 - INFO - root: Evaluating...
22-11-05 16:33:34 - INFO - root: ***** Transfer task : TREC *****


22-11-05 16:33:36 - INFO - root: Computed train embeddings
22-11-05 16:33:36 - INFO - root: Computed test embeddings
22-11-05 16:33:36 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with 5-fold cross-validation
22-11-05 16:33:54 - INFO - root: [('reg:1e-05', 73.64), ('reg:0.0001', 72.65), ('reg:0.001', 73.2), ('reg:0.01', 71.86)]
22-11-05 16:33:54 - INFO - root: Cross-validation : best param found is reg = 1e-05             with score 73.64
22-11-05 16:33:54 - INFO - root: Evaluating...
22-11-05 16:33:56 - INFO - root: ***** Transfer task : MRPC *****


22-11-05 16:33:56 - INFO - root: Computing embedding for train
22-11-05 16:33:59 - INFO - root: Computed train embeddings
22-11-05 16:33:59 - INFO - root: Computing embedding for test
22-11-05 16:34:01 - INFO - root: Computed test embeddings
22-11-05 16:34:01 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with 5-fold cross-validation
22-11-05 16:34:12 - INFO - root: [('reg:1e-05', 72.13), ('reg:0.0001', 71.64), ('reg:0.001', 71.86), ('reg:0.01', 72.03)]
22-11-05 16:34:12 - INFO - root: Cross-validation : best param found is reg = 1e-05             with score 72.13
22-11-05 16:34:12 - INFO - root: Evaluating...
22-11-18 14:30:49 - INFO - sentence_transformers.SentenceTransformer: Load pretrained SentenceTransformer: paraphrase-multilingual-MiniLM-L12-v2
22-11-18 14:30:50 - INFO - sentence_transformers.SentenceTransformer: Use pytorch device: cuda
22-11-18 14:30:50 - INFO - __main__: SBert model paraphrase-multilingual-MiniLM-L12-v2 is loaded.
22-11-18 14:30:52 - INFO - __main__: Num of SBert features: 384
