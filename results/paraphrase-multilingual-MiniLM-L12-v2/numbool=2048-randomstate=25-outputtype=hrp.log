22-11-06 04:22:03 - INFO - sentence_transformers.SentenceTransformer: Load pretrained SentenceTransformer: paraphrase-multilingual-MiniLM-L12-v2
22-11-06 04:22:05 - INFO - sentence_transformers.SentenceTransformer: Use pytorch device: cuda
22-11-06 04:22:05 - INFO - __main__: SBert model paraphrase-multilingual-MiniLM-L12-v2 is loaded.
22-11-06 04:22:07 - INFO - __main__: Num of SBert features: 384
22-11-06 04:22:08 - INFO - root: Generating sentence embeddings
22-11-06 04:22:13 - INFO - root: Generated sentence embeddings
22-11-06 04:22:13 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation
22-11-06 04:22:39 - INFO - root: Best param found at split 1: l2reg = 1e-05                 with score 78.59
22-11-06 04:23:07 - INFO - root: Best param found at split 2: l2reg = 0.01                 with score 78.16
22-11-06 04:23:36 - INFO - root: Best param found at split 3: l2reg = 0.001                 with score 77.5
22-11-06 04:24:06 - INFO - root: Best param found at split 4: l2reg = 0.01                 with score 78.68
22-11-06 04:24:33 - INFO - root: Best param found at split 5: l2reg = 0.001                 with score 77.9
22-11-06 04:24:35 - INFO - root: Generating sentence embeddings
22-11-06 04:24:36 - INFO - root: Generated sentence embeddings
22-11-06 04:24:36 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation
22-11-06 04:24:45 - INFO - root: Best param found at split 1: l2reg = 1e-05                 with score 87.98
22-11-06 04:24:54 - INFO - root: Best param found at split 2: l2reg = 0.01                 with score 88.31
22-11-06 04:25:03 - INFO - root: Best param found at split 3: l2reg = 0.01                 with score 87.48
22-11-06 04:25:14 - INFO - root: Best param found at split 4: l2reg = 0.01                 with score 87.91
22-11-06 04:25:23 - INFO - root: Best param found at split 5: l2reg = 1e-05                 with score 88.15
22-11-06 04:25:23 - INFO - root: Generating sentence embeddings
22-11-06 04:25:28 - INFO - root: Generated sentence embeddings
22-11-06 04:25:28 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation
22-11-06 04:25:52 - INFO - root: Best param found at split 1: l2reg = 1e-05                 with score 91.56
22-11-06 04:26:18 - INFO - root: Best param found at split 2: l2reg = 1e-05                 with score 91.9
22-11-06 04:26:50 - INFO - root: Best param found at split 3: l2reg = 0.0001                 with score 91.59
22-11-06 04:27:14 - INFO - root: Best param found at split 4: l2reg = 0.001                 with score 91.62
22-11-06 04:27:42 - INFO - root: Best param found at split 5: l2reg = 0.001                 with score 91.44
22-11-06 04:27:43 - INFO - root: Generating sentence embeddings
22-11-06 04:27:47 - INFO - root: Generated sentence embeddings
22-11-06 04:27:47 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation
22-11-06 04:28:16 - INFO - root: Best param found at split 1: l2reg = 1e-05                 with score 88.17
22-11-06 04:28:44 - INFO - root: Best param found at split 2: l2reg = 0.0001                 with score 88.99
22-11-06 04:29:14 - INFO - root: Best param found at split 3: l2reg = 0.001                 with score 88.96
22-11-06 04:29:40 - INFO - root: Best param found at split 4: l2reg = 1e-05                 with score 89.15
22-11-06 04:30:09 - INFO - root: Best param found at split 5: l2reg = 0.001                 with score 89.11
22-11-06 04:30:11 - INFO - root: Computing embedding for train
22-11-06 04:30:14 - INFO - root: Computed train embeddings
22-11-06 04:30:14 - INFO - root: Computing embedding for dev
22-11-06 04:30:15 - INFO - root: Computed dev embeddings
22-11-06 04:30:15 - INFO - root: Computing embedding for test
22-11-06 04:30:16 - INFO - root: Computed test embeddings
22-11-06 04:30:16 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with standard validation..
22-11-06 04:30:22 - INFO - root: [('reg:1e-05', 41.14), ('reg:0.0001', 38.96), ('reg:0.001', 41.96), ('reg:0.01', 41.87)]
22-11-06 04:30:22 - INFO - root: Validation : best param found is reg = 0.001 with score             41.96
22-11-06 04:30:22 - INFO - root: Evaluating...
22-11-06 04:30:23 - INFO - root: ***** Transfer task : TREC *****


22-11-06 04:30:25 - INFO - root: Computed train embeddings
22-11-06 04:30:26 - INFO - root: Computed test embeddings
22-11-06 04:30:26 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with 5-fold cross-validation
22-11-06 04:30:45 - INFO - root: [('reg:1e-05', 77.73), ('reg:0.0001', 79.9), ('reg:0.001', 77.22), ('reg:0.01', 76.08)]
22-11-06 04:30:45 - INFO - root: Cross-validation : best param found is reg = 0.0001             with score 79.9
22-11-06 04:30:45 - INFO - root: Evaluating...
22-11-06 04:30:46 - INFO - root: ***** Transfer task : MRPC *****


22-11-06 04:30:46 - INFO - root: Computing embedding for train
22-11-06 04:30:49 - INFO - root: Computed train embeddings
22-11-06 04:30:49 - INFO - root: Computing embedding for test
22-11-06 04:30:51 - INFO - root: Computed test embeddings
22-11-06 04:30:51 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with 5-fold cross-validation
22-11-06 04:31:01 - INFO - root: [('reg:1e-05', 73.55), ('reg:0.0001', 73.99), ('reg:0.001', 73.53), ('reg:0.01', 71.37)]
22-11-06 04:31:01 - INFO - root: Cross-validation : best param found is reg = 0.0001             with score 73.99
22-11-06 04:31:01 - INFO - root: Evaluating...
22-11-18 19:03:33 - INFO - sentence_transformers.SentenceTransformer: Load pretrained SentenceTransformer: paraphrase-multilingual-MiniLM-L12-v2
22-11-18 19:03:35 - INFO - sentence_transformers.SentenceTransformer: Use pytorch device: cuda
22-11-18 19:03:35 - INFO - __main__: SBert model paraphrase-multilingual-MiniLM-L12-v2 is loaded.
22-11-18 19:03:37 - INFO - __main__: Num of SBert features: 384
