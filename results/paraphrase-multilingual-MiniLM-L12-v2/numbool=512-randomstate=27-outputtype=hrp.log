22-11-05 11:03:21 - INFO - sentence_transformers.SentenceTransformer: Load pretrained SentenceTransformer: paraphrase-multilingual-MiniLM-L12-v2
22-11-05 11:03:23 - INFO - sentence_transformers.SentenceTransformer: Use pytorch device: cuda
22-11-05 11:03:23 - INFO - __main__: SBert model paraphrase-multilingual-MiniLM-L12-v2 is loaded.
22-11-05 11:03:25 - INFO - __main__: Num of SBert features: 384
22-11-05 11:03:26 - INFO - root: Generating sentence embeddings
22-11-05 11:03:30 - INFO - root: Generated sentence embeddings
22-11-05 11:03:30 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation
22-11-05 11:03:59 - INFO - root: Best param found at split 1: l2reg = 0.001                 with score 77.04
22-11-05 11:04:28 - INFO - root: Best param found at split 2: l2reg = 0.0001                 with score 77.04
22-11-05 11:04:55 - INFO - root: Best param found at split 3: l2reg = 0.01                 with score 76.48
22-11-05 11:05:24 - INFO - root: Best param found at split 4: l2reg = 0.001                 with score 76.62
22-11-05 11:05:55 - INFO - root: Best param found at split 5: l2reg = 0.001                 with score 76.55
22-11-05 11:05:56 - INFO - root: Generating sentence embeddings
22-11-05 11:05:58 - INFO - root: Generated sentence embeddings
22-11-05 11:05:58 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation
22-11-05 11:06:06 - INFO - root: Best param found at split 1: l2reg = 0.0001                 with score 87.62
22-11-05 11:06:16 - INFO - root: Best param found at split 2: l2reg = 1e-05                 with score 87.98
22-11-05 11:06:25 - INFO - root: Best param found at split 3: l2reg = 0.01                 with score 87.52
22-11-05 11:06:36 - INFO - root: Best param found at split 4: l2reg = 0.0001                 with score 87.28
22-11-05 11:06:45 - INFO - root: Best param found at split 5: l2reg = 0.0001                 with score 86.69
22-11-05 11:06:45 - INFO - root: Generating sentence embeddings
22-11-05 11:06:50 - INFO - root: Generated sentence embeddings
22-11-05 11:06:50 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation
22-11-05 11:07:15 - INFO - root: Best param found at split 1: l2reg = 0.01                 with score 90.19
22-11-05 11:07:42 - INFO - root: Best param found at split 2: l2reg = 0.01                 with score 90.28
22-11-05 11:08:08 - INFO - root: Best param found at split 3: l2reg = 0.01                 with score 90.18
22-11-05 11:08:33 - INFO - root: Best param found at split 4: l2reg = 0.001                 with score 89.98
22-11-05 11:08:59 - INFO - root: Best param found at split 5: l2reg = 0.01                 with score 89.86
22-11-05 11:09:01 - INFO - root: Generating sentence embeddings
22-11-05 11:09:04 - INFO - root: Generated sentence embeddings
22-11-05 11:09:04 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation
22-11-05 11:09:29 - INFO - root: Best param found at split 1: l2reg = 0.01                 with score 88.58
22-11-05 11:09:57 - INFO - root: Best param found at split 2: l2reg = 0.01                 with score 87.47
22-11-05 11:10:27 - INFO - root: Best param found at split 3: l2reg = 0.001                 with score 88.12
22-11-05 11:10:54 - INFO - root: Best param found at split 4: l2reg = 0.0001                 with score 87.67
22-11-05 11:11:25 - INFO - root: Best param found at split 5: l2reg = 0.0001                 with score 85.6
22-11-05 11:11:27 - INFO - root: Computing embedding for train
22-11-05 11:11:31 - INFO - root: Computed train embeddings
22-11-05 11:11:31 - INFO - root: Computing embedding for dev
22-11-05 11:11:31 - INFO - root: Computed dev embeddings
22-11-05 11:11:31 - INFO - root: Computing embedding for test
22-11-05 11:11:32 - INFO - root: Computed test embeddings
22-11-05 11:11:32 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with standard validation..
22-11-05 11:11:38 - INFO - root: [('reg:1e-05', 40.51), ('reg:0.0001', 39.24), ('reg:0.001', 40.69), ('reg:0.01', 36.33)]
22-11-05 11:11:38 - INFO - root: Validation : best param found is reg = 0.001 with score             40.69
22-11-05 11:11:38 - INFO - root: Evaluating...
22-11-05 11:11:40 - INFO - root: ***** Transfer task : TREC *****


22-11-05 11:11:42 - INFO - root: Computed train embeddings
22-11-05 11:11:42 - INFO - root: Computed test embeddings
22-11-05 11:11:42 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with 5-fold cross-validation
22-11-05 11:12:00 - INFO - root: [('reg:1e-05', 72.91), ('reg:0.0001', 72.96), ('reg:0.001', 73.55), ('reg:0.01', 70.87)]
22-11-05 11:12:00 - INFO - root: Cross-validation : best param found is reg = 0.001             with score 73.55
22-11-05 11:12:00 - INFO - root: Evaluating...
22-11-05 11:12:01 - INFO - root: ***** Transfer task : MRPC *****


22-11-05 11:12:01 - INFO - root: Computing embedding for train
22-11-05 11:12:05 - INFO - root: Computed train embeddings
22-11-05 11:12:05 - INFO - root: Computing embedding for test
22-11-05 11:12:06 - INFO - root: Computed test embeddings
22-11-05 11:12:06 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with 5-fold cross-validation
22-11-05 11:12:19 - INFO - root: [('reg:1e-05', 72.62), ('reg:0.0001', 72.6), ('reg:0.001', 72.64), ('reg:0.01', 72.62)]
22-11-05 11:12:19 - INFO - root: Cross-validation : best param found is reg = 0.001             with score 72.64
22-11-05 11:12:19 - INFO - root: Evaluating...
22-11-18 12:28:37 - INFO - sentence_transformers.SentenceTransformer: Load pretrained SentenceTransformer: paraphrase-multilingual-MiniLM-L12-v2
22-11-18 12:28:39 - INFO - sentence_transformers.SentenceTransformer: Use pytorch device: cuda
22-11-18 12:28:39 - INFO - __main__: SBert model paraphrase-multilingual-MiniLM-L12-v2 is loaded.
22-11-18 12:28:40 - INFO - __main__: Num of SBert features: 384
