22-11-06 00:10:23 - INFO - sentence_transformers.SentenceTransformer: Load pretrained SentenceTransformer: paraphrase-multilingual-MiniLM-L12-v2
22-11-06 00:10:25 - INFO - sentence_transformers.SentenceTransformer: Use pytorch device: cuda
22-11-06 00:10:25 - INFO - __main__: SBert model paraphrase-multilingual-MiniLM-L12-v2 is loaded.
22-11-06 00:10:27 - INFO - __main__: Num of SBert features: 384
22-11-06 00:10:28 - INFO - root: Generating sentence embeddings
22-11-06 00:10:32 - INFO - root: Generated sentence embeddings
22-11-06 00:10:32 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation
22-11-06 00:11:01 - INFO - root: Best param found at split 1: l2reg = 0.01                 with score 76.36
22-11-06 00:11:26 - INFO - root: Best param found at split 2: l2reg = 0.01                 with score 77.63
22-11-06 00:11:56 - INFO - root: Best param found at split 3: l2reg = 0.01                 with score 77.69
22-11-06 00:12:28 - INFO - root: Best param found at split 4: l2reg = 0.01                 with score 78.23
22-11-06 00:13:00 - INFO - root: Best param found at split 5: l2reg = 1e-05                 with score 77.05
22-11-06 00:13:01 - INFO - root: Generating sentence embeddings
22-11-06 00:13:03 - INFO - root: Generated sentence embeddings
22-11-06 00:13:03 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation
22-11-06 00:13:13 - INFO - root: Best param found at split 1: l2reg = 0.0001                 with score 87.78
22-11-06 00:13:24 - INFO - root: Best param found at split 2: l2reg = 0.001                 with score 88.91
22-11-06 00:13:34 - INFO - root: Best param found at split 3: l2reg = 0.01                 with score 87.81
22-11-06 00:13:44 - INFO - root: Best param found at split 4: l2reg = 0.01                 with score 88.34
22-11-06 00:13:54 - INFO - root: Best param found at split 5: l2reg = 1e-05                 with score 87.45
22-11-06 00:13:55 - INFO - root: Generating sentence embeddings
22-11-06 00:13:59 - INFO - root: Generated sentence embeddings
22-11-06 00:13:59 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation
22-11-06 00:14:23 - INFO - root: Best param found at split 1: l2reg = 0.01                 with score 91.5
22-11-06 00:14:51 - INFO - root: Best param found at split 2: l2reg = 0.001                 with score 91.69
22-11-06 00:15:18 - INFO - root: Best param found at split 3: l2reg = 0.001                 with score 91.6
22-11-06 00:15:43 - INFO - root: Best param found at split 4: l2reg = 0.01                 with score 91.54
22-11-06 00:16:11 - INFO - root: Best param found at split 5: l2reg = 0.01                 with score 91.39
22-11-06 00:16:12 - INFO - root: Generating sentence embeddings
22-11-06 00:16:16 - INFO - root: Generated sentence embeddings
22-11-06 00:16:16 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation
22-11-06 00:16:44 - INFO - root: Best param found at split 1: l2reg = 0.01                 with score 89.09
22-11-06 00:17:13 - INFO - root: Best param found at split 2: l2reg = 1e-05                 with score 88.7
22-11-06 00:17:40 - INFO - root: Best param found at split 3: l2reg = 0.01                 with score 89.11
22-11-06 00:18:09 - INFO - root: Best param found at split 4: l2reg = 1e-05                 with score 88.89
22-11-06 00:18:37 - INFO - root: Best param found at split 5: l2reg = 0.001                 with score 88.97
22-11-06 00:18:39 - INFO - root: Computing embedding for train
22-11-06 00:18:42 - INFO - root: Computed train embeddings
22-11-06 00:18:42 - INFO - root: Computing embedding for dev
22-11-06 00:18:43 - INFO - root: Computed dev embeddings
22-11-06 00:18:43 - INFO - root: Computing embedding for test
22-11-06 00:18:44 - INFO - root: Computed test embeddings
22-11-06 00:18:44 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with standard validation..
22-11-06 00:18:50 - INFO - root: [('reg:1e-05', 38.69), ('reg:0.0001', 40.69), ('reg:0.001', 39.78), ('reg:0.01', 41.05)]
22-11-06 00:18:50 - INFO - root: Validation : best param found is reg = 0.01 with score             41.05
22-11-06 00:18:50 - INFO - root: Evaluating...
22-11-06 00:18:51 - INFO - root: ***** Transfer task : TREC *****


22-11-06 00:18:53 - INFO - root: Computed train embeddings
22-11-06 00:18:53 - INFO - root: Computed test embeddings
22-11-06 00:18:53 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with 5-fold cross-validation
22-11-06 00:19:12 - INFO - root: [('reg:1e-05', 75.79), ('reg:0.0001', 77.03), ('reg:0.001', 78.49), ('reg:0.01', 70.34)]
22-11-06 00:19:12 - INFO - root: Cross-validation : best param found is reg = 0.001             with score 78.49
22-11-06 00:19:12 - INFO - root: Evaluating...
22-11-06 00:19:13 - INFO - root: ***** Transfer task : MRPC *****


22-11-06 00:19:13 - INFO - root: Computing embedding for train
22-11-06 00:19:17 - INFO - root: Computed train embeddings
22-11-06 00:19:17 - INFO - root: Computing embedding for test
22-11-06 00:19:18 - INFO - root: Computed test embeddings
22-11-06 00:19:18 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with 5-fold cross-validation
22-11-06 00:19:25 - INFO - root: [('reg:1e-05', 74.78), ('reg:0.0001', 74.22), ('reg:0.001', 73.45), ('reg:0.01', 72.89)]
22-11-06 00:19:25 - INFO - root: Cross-validation : best param found is reg = 1e-05             with score 74.78
22-11-06 00:19:25 - INFO - root: Evaluating...
22-11-18 17:25:29 - INFO - sentence_transformers.SentenceTransformer: Load pretrained SentenceTransformer: paraphrase-multilingual-MiniLM-L12-v2
22-11-18 17:25:31 - INFO - sentence_transformers.SentenceTransformer: Use pytorch device: cuda
22-11-18 17:25:31 - INFO - __main__: SBert model paraphrase-multilingual-MiniLM-L12-v2 is loaded.
22-11-18 17:25:32 - INFO - __main__: Num of SBert features: 384
