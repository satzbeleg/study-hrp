22-11-06 02:58:15 - INFO - sentence_transformers.SentenceTransformer: Load pretrained SentenceTransformer: paraphrase-multilingual-MiniLM-L12-v2
22-11-06 02:58:16 - INFO - sentence_transformers.SentenceTransformer: Use pytorch device: cuda
22-11-06 02:58:16 - INFO - __main__: SBert model paraphrase-multilingual-MiniLM-L12-v2 is loaded.
22-11-06 02:58:19 - INFO - __main__: Num of SBert features: 384
22-11-06 02:58:19 - INFO - root: Generating sentence embeddings
22-11-06 02:58:24 - INFO - root: Generated sentence embeddings
22-11-06 02:58:24 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation
22-11-06 02:58:49 - INFO - root: Best param found at split 1: l2reg = 0.01                 with score 78.09
22-11-06 02:59:17 - INFO - root: Best param found at split 2: l2reg = 0.0001                 with score 78.5
22-11-06 02:59:46 - INFO - root: Best param found at split 3: l2reg = 1e-05                 with score 76.96
22-11-06 03:00:13 - INFO - root: Best param found at split 4: l2reg = 1e-05                 with score 77.97
22-11-06 03:00:43 - INFO - root: Best param found at split 5: l2reg = 0.001                 with score 77.96
22-11-06 03:00:44 - INFO - root: Generating sentence embeddings
22-11-06 03:00:46 - INFO - root: Generated sentence embeddings
22-11-06 03:00:46 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation
22-11-06 03:00:54 - INFO - root: Best param found at split 1: l2reg = 0.001                 with score 88.25
22-11-06 03:01:05 - INFO - root: Best param found at split 2: l2reg = 1e-05                 with score 88.77
22-11-06 03:01:14 - INFO - root: Best param found at split 3: l2reg = 0.01                 with score 87.85
22-11-06 03:01:24 - INFO - root: Best param found at split 4: l2reg = 1e-05                 with score 88.01
22-11-06 03:01:33 - INFO - root: Best param found at split 5: l2reg = 0.001                 with score 88.15
22-11-06 03:01:34 - INFO - root: Generating sentence embeddings
22-11-06 03:01:38 - INFO - root: Generated sentence embeddings
22-11-06 03:01:38 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation
22-11-06 03:02:03 - INFO - root: Best param found at split 1: l2reg = 1e-05                 with score 91.41
22-11-06 03:02:31 - INFO - root: Best param found at split 2: l2reg = 1e-05                 with score 92.07
22-11-06 03:02:59 - INFO - root: Best param found at split 3: l2reg = 0.01                 with score 91.6
22-11-06 03:03:27 - INFO - root: Best param found at split 4: l2reg = 0.001                 with score 91.38
22-11-06 03:03:55 - INFO - root: Best param found at split 5: l2reg = 1e-05                 with score 91.35
22-11-06 03:03:57 - INFO - root: Generating sentence embeddings
22-11-06 03:04:00 - INFO - root: Generated sentence embeddings
22-11-06 03:04:00 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation
22-11-06 03:04:26 - INFO - root: Best param found at split 1: l2reg = 0.001                 with score 88.86
22-11-06 03:04:51 - INFO - root: Best param found at split 2: l2reg = 0.0001                 with score 88.46
22-11-06 03:05:22 - INFO - root: Best param found at split 3: l2reg = 1e-05                 with score 89.02
22-11-06 03:05:50 - INFO - root: Best param found at split 4: l2reg = 1e-05                 with score 88.78
22-11-06 03:06:17 - INFO - root: Best param found at split 5: l2reg = 0.0001                 with score 87.71
22-11-06 03:06:18 - INFO - root: Computing embedding for train
22-11-06 03:06:22 - INFO - root: Computed train embeddings
22-11-06 03:06:22 - INFO - root: Computing embedding for dev
22-11-06 03:06:22 - INFO - root: Computed dev embeddings
22-11-06 03:06:22 - INFO - root: Computing embedding for test
22-11-06 03:06:23 - INFO - root: Computed test embeddings
22-11-06 03:06:23 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with standard validation..
22-11-06 03:06:28 - INFO - root: [('reg:1e-05', 40.96), ('reg:0.0001', 42.33), ('reg:0.001', 39.6), ('reg:0.01', 42.51)]
22-11-06 03:06:28 - INFO - root: Validation : best param found is reg = 0.01 with score             42.51
22-11-06 03:06:28 - INFO - root: Evaluating...
22-11-06 03:06:30 - INFO - root: ***** Transfer task : TREC *****


22-11-06 03:06:32 - INFO - root: Computed train embeddings
22-11-06 03:06:32 - INFO - root: Computed test embeddings
22-11-06 03:06:32 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with 5-fold cross-validation
22-11-06 03:06:50 - INFO - root: [('reg:1e-05', 76.21), ('reg:0.0001', 77.73), ('reg:0.001', 76.58), ('reg:0.01', 70.8)]
22-11-06 03:06:50 - INFO - root: Cross-validation : best param found is reg = 0.0001             with score 77.73
22-11-06 03:06:50 - INFO - root: Evaluating...
22-11-06 03:06:51 - INFO - root: ***** Transfer task : MRPC *****


22-11-06 03:06:51 - INFO - root: Computing embedding for train
22-11-06 03:06:55 - INFO - root: Computed train embeddings
22-11-06 03:06:55 - INFO - root: Computing embedding for test
22-11-06 03:06:56 - INFO - root: Computed test embeddings
22-11-06 03:06:56 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with 5-fold cross-validation
22-11-06 03:07:10 - INFO - root: [('reg:1e-05', 73.06), ('reg:0.0001', 73.75), ('reg:0.001', 73.77), ('reg:0.01', 73.94)]
22-11-06 03:07:10 - INFO - root: Cross-validation : best param found is reg = 0.01             with score 73.94
22-11-06 03:07:10 - INFO - root: Evaluating...
22-11-18 18:29:02 - INFO - sentence_transformers.SentenceTransformer: Load pretrained SentenceTransformer: paraphrase-multilingual-MiniLM-L12-v2
22-11-18 18:29:03 - INFO - sentence_transformers.SentenceTransformer: Use pytorch device: cuda
22-11-18 18:29:03 - INFO - __main__: SBert model paraphrase-multilingual-MiniLM-L12-v2 is loaded.
22-11-18 18:29:05 - INFO - __main__: Num of SBert features: 384
