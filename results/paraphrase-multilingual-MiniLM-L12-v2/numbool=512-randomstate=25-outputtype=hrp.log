22-11-05 10:10:09 - INFO - sentence_transformers.SentenceTransformer: Load pretrained SentenceTransformer: paraphrase-multilingual-MiniLM-L12-v2
22-11-05 10:10:10 - INFO - sentence_transformers.SentenceTransformer: Use pytorch device: cuda
22-11-05 10:10:10 - INFO - __main__: SBert model paraphrase-multilingual-MiniLM-L12-v2 is loaded.
22-11-05 10:10:12 - INFO - __main__: Num of SBert features: 384
22-11-05 10:10:13 - INFO - root: Generating sentence embeddings
22-11-05 10:10:17 - INFO - root: Generated sentence embeddings
22-11-05 10:10:17 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation
22-11-05 10:10:47 - INFO - root: Best param found at split 1: l2reg = 0.001                 with score 77.95
22-11-05 10:11:14 - INFO - root: Best param found at split 2: l2reg = 1e-05                 with score 76.4
22-11-05 10:11:44 - INFO - root: Best param found at split 3: l2reg = 0.001                 with score 78.08
22-11-05 10:12:14 - INFO - root: Best param found at split 4: l2reg = 0.01                 with score 77.28
22-11-05 10:12:47 - INFO - root: Best param found at split 5: l2reg = 1e-05                 with score 76.21
22-11-05 10:12:49 - INFO - root: Generating sentence embeddings
22-11-05 10:12:50 - INFO - root: Generated sentence embeddings
22-11-05 10:12:50 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation
22-11-05 10:12:59 - INFO - root: Best param found at split 1: l2reg = 0.001                 with score 87.25
22-11-05 10:13:08 - INFO - root: Best param found at split 2: l2reg = 0.001                 with score 87.52
22-11-05 10:13:19 - INFO - root: Best param found at split 3: l2reg = 0.01                 with score 87.38
22-11-05 10:13:29 - INFO - root: Best param found at split 4: l2reg = 0.01                 with score 86.99
22-11-05 10:13:39 - INFO - root: Best param found at split 5: l2reg = 1e-05                 with score 87.68
22-11-05 10:13:40 - INFO - root: Generating sentence embeddings
22-11-05 10:13:44 - INFO - root: Generated sentence embeddings
22-11-05 10:13:44 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation
22-11-05 10:14:09 - INFO - root: Best param found at split 1: l2reg = 0.01                 with score 90.14
22-11-05 10:14:35 - INFO - root: Best param found at split 2: l2reg = 0.01                 with score 90.14
22-11-05 10:15:02 - INFO - root: Best param found at split 3: l2reg = 0.001                 with score 90.31
22-11-05 10:15:27 - INFO - root: Best param found at split 4: l2reg = 0.001                 with score 89.52
22-11-05 10:15:53 - INFO - root: Best param found at split 5: l2reg = 0.01                 with score 89.78
22-11-05 10:15:55 - INFO - root: Generating sentence embeddings
22-11-05 10:15:58 - INFO - root: Generated sentence embeddings
22-11-05 10:15:58 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation
22-11-05 10:16:22 - INFO - root: Best param found at split 1: l2reg = 0.01                 with score 88.43
22-11-05 10:16:53 - INFO - root: Best param found at split 2: l2reg = 0.0001                 with score 87.79
22-11-05 10:17:24 - INFO - root: Best param found at split 3: l2reg = 0.0001                 with score 87.73
22-11-05 10:17:54 - INFO - root: Best param found at split 4: l2reg = 0.001                 with score 87.54
22-11-05 10:18:22 - INFO - root: Best param found at split 5: l2reg = 0.01                 with score 86.35
22-11-05 10:18:24 - INFO - root: Computing embedding for train
22-11-05 10:18:27 - INFO - root: Computed train embeddings
22-11-05 10:18:27 - INFO - root: Computing embedding for dev
22-11-05 10:18:28 - INFO - root: Computed dev embeddings
22-11-05 10:18:28 - INFO - root: Computing embedding for test
22-11-05 10:18:29 - INFO - root: Computed test embeddings
22-11-05 10:18:29 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with standard validation..
22-11-05 10:18:35 - INFO - root: [('reg:1e-05', 41.14), ('reg:0.0001', 42.23), ('reg:0.001', 42.14), ('reg:0.01', 41.33)]
22-11-05 10:18:35 - INFO - root: Validation : best param found is reg = 0.0001 with score             42.23
22-11-05 10:18:35 - INFO - root: Evaluating...
22-11-05 10:18:37 - INFO - root: ***** Transfer task : TREC *****


22-11-05 10:18:39 - INFO - root: Computed train embeddings
22-11-05 10:18:39 - INFO - root: Computed test embeddings
22-11-05 10:18:39 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with 5-fold cross-validation
22-11-05 10:18:57 - INFO - root: [('reg:1e-05', 71.48), ('reg:0.0001', 71.02), ('reg:0.001', 71.02), ('reg:0.01', 69.94)]
22-11-05 10:18:57 - INFO - root: Cross-validation : best param found is reg = 1e-05             with score 71.48
22-11-05 10:18:57 - INFO - root: Evaluating...
22-11-05 10:18:58 - INFO - root: ***** Transfer task : MRPC *****


22-11-05 10:18:58 - INFO - root: Computing embedding for train
22-11-05 10:19:02 - INFO - root: Computed train embeddings
22-11-05 10:19:02 - INFO - root: Computing embedding for test
22-11-05 10:19:03 - INFO - root: Computed test embeddings
22-11-05 10:19:03 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with 5-fold cross-validation
22-11-05 10:19:16 - INFO - root: [('reg:1e-05', 72.67), ('reg:0.0001', 72.67), ('reg:0.001', 72.57), ('reg:0.01', 73.33)]
22-11-05 10:19:16 - INFO - root: Cross-validation : best param found is reg = 0.01             with score 73.33
22-11-05 10:19:16 - INFO - root: Evaluating...
22-11-18 12:09:02 - INFO - sentence_transformers.SentenceTransformer: Load pretrained SentenceTransformer: paraphrase-multilingual-MiniLM-L12-v2
22-11-18 12:09:03 - INFO - sentence_transformers.SentenceTransformer: Use pytorch device: cuda
22-11-18 12:09:03 - INFO - __main__: SBert model paraphrase-multilingual-MiniLM-L12-v2 is loaded.
22-11-18 12:09:05 - INFO - __main__: Num of SBert features: 384
