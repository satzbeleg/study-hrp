22-11-05 00:02:02 - INFO - sentence_transformers.SentenceTransformer: Load pretrained SentenceTransformer: paraphrase-multilingual-MiniLM-L12-v2
22-11-05 00:02:04 - INFO - sentence_transformers.SentenceTransformer: Use pytorch device: cuda
22-11-05 00:02:04 - INFO - __main__: SBert model paraphrase-multilingual-MiniLM-L12-v2 is loaded.
22-11-05 00:02:06 - INFO - __main__: Num of SBert features: 384
22-11-05 00:02:06 - INFO - root: Generating sentence embeddings
22-11-05 00:02:10 - INFO - root: Generated sentence embeddings
22-11-05 00:02:10 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation
22-11-05 00:02:36 - INFO - root: Best param found at split 1: l2reg = 0.0001                 with score 80.02
22-11-05 00:03:06 - INFO - root: Best param found at split 2: l2reg = 0.0001                 with score 80.19
22-11-05 00:03:37 - INFO - root: Best param found at split 3: l2reg = 1e-05                 with score 80.05
22-11-05 00:03:58 - INFO - root: Best param found at split 4: l2reg = 0.001                 with score 79.23
22-11-05 00:04:27 - INFO - root: Best param found at split 5: l2reg = 0.001                 with score 79.5
22-11-05 00:04:29 - INFO - root: Generating sentence embeddings
22-11-05 00:04:31 - INFO - root: Generated sentence embeddings
22-11-05 00:04:31 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation
22-11-05 00:04:40 - INFO - root: Best param found at split 1: l2reg = 0.01                 with score 89.3
22-11-05 00:04:50 - INFO - root: Best param found at split 2: l2reg = 1e-05                 with score 89.4
22-11-05 00:05:00 - INFO - root: Best param found at split 3: l2reg = 0.01                 with score 88.61
22-11-05 00:05:09 - INFO - root: Best param found at split 4: l2reg = 0.01                 with score 89.34
22-11-05 00:05:17 - INFO - root: Best param found at split 5: l2reg = 0.01                 with score 89.01
22-11-05 00:05:17 - INFO - root: Generating sentence embeddings
22-11-05 00:05:21 - INFO - root: Generated sentence embeddings
22-11-05 00:05:21 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation
22-11-05 00:05:50 - INFO - root: Best param found at split 1: l2reg = 0.001                 with score 92.64
22-11-05 00:06:22 - INFO - root: Best param found at split 2: l2reg = 1e-05                 with score 92.81
22-11-05 00:06:52 - INFO - root: Best param found at split 3: l2reg = 0.0001                 with score 92.65
22-11-05 00:07:24 - INFO - root: Best param found at split 4: l2reg = 0.001                 with score 92.55
22-11-05 00:07:55 - INFO - root: Best param found at split 5: l2reg = 0.001                 with score 92.45
22-11-05 00:07:57 - INFO - root: Generating sentence embeddings
22-11-05 00:08:00 - INFO - root: Generated sentence embeddings
22-11-05 00:08:00 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation
22-11-05 00:08:25 - INFO - root: Best param found at split 1: l2reg = 0.0001                 with score 89.27
22-11-05 00:08:51 - INFO - root: Best param found at split 2: l2reg = 0.001                 with score 88.8
22-11-05 00:09:19 - INFO - root: Best param found at split 3: l2reg = 0.0001                 with score 89.51
22-11-05 00:09:45 - INFO - root: Best param found at split 4: l2reg = 0.001                 with score 89.07
22-11-05 00:10:17 - INFO - root: Best param found at split 5: l2reg = 0.001                 with score 89.16
22-11-05 00:10:18 - INFO - root: Computing embedding for train
22-11-05 00:10:21 - INFO - root: Computed train embeddings
22-11-05 00:10:21 - INFO - root: Computing embedding for dev
22-11-05 00:10:22 - INFO - root: Computed dev embeddings
22-11-05 00:10:22 - INFO - root: Computing embedding for test
22-11-05 00:10:22 - INFO - root: Computed test embeddings
22-11-05 00:10:22 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with standard validation..
22-11-05 00:10:29 - INFO - root: [('reg:1e-05', 45.59), ('reg:0.0001', 45.87), ('reg:0.001', 45.59), ('reg:0.01', 45.78)]
22-11-05 00:10:29 - INFO - root: Validation : best param found is reg = 0.0001 with score             45.87
22-11-05 00:10:29 - INFO - root: Evaluating...
22-11-05 00:10:31 - INFO - root: ***** Transfer task : TREC *****


22-11-05 00:10:32 - INFO - root: Computed train embeddings
22-11-05 00:10:33 - INFO - root: Computed test embeddings
22-11-05 00:10:33 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with 5-fold cross-validation
22-11-05 00:10:53 - INFO - root: [('reg:1e-05', 83.6), ('reg:0.0001', 83.57), ('reg:0.001', 83.03), ('reg:0.01', 79.46)]
22-11-05 00:10:53 - INFO - root: Cross-validation : best param found is reg = 1e-05             with score 83.6
22-11-05 00:10:53 - INFO - root: Evaluating...
22-11-05 00:10:54 - INFO - root: ***** Transfer task : MRPC *****


22-11-05 00:10:55 - INFO - root: Computing embedding for train
22-11-05 00:10:58 - INFO - root: Computed train embeddings
22-11-05 00:10:58 - INFO - root: Computing embedding for test
22-11-05 00:10:59 - INFO - root: Computed test embeddings
22-11-05 00:10:59 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with 5-fold cross-validation
22-11-05 00:11:10 - INFO - root: [('reg:1e-05', 74.75), ('reg:0.0001', 74.78), ('reg:0.001', 74.85), ('reg:0.01', 74.98)]
22-11-05 00:11:10 - INFO - root: Cross-validation : best param found is reg = 0.01             with score 74.98
22-11-05 00:11:10 - INFO - root: Evaluating...
22-11-18 08:19:31 - INFO - sentence_transformers.SentenceTransformer: Load pretrained SentenceTransformer: paraphrase-multilingual-MiniLM-L12-v2
22-11-18 08:19:33 - INFO - sentence_transformers.SentenceTransformer: Use pytorch device: cuda
22-11-18 08:19:33 - INFO - __main__: SBert model paraphrase-multilingual-MiniLM-L12-v2 is loaded.
22-11-18 08:19:35 - INFO - __main__: Num of SBert features: 384
