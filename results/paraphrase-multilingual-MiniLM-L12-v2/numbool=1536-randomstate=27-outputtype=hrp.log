22-11-06 00:38:25 - INFO - sentence_transformers.SentenceTransformer: Load pretrained SentenceTransformer: paraphrase-multilingual-MiniLM-L12-v2
22-11-06 00:38:27 - INFO - sentence_transformers.SentenceTransformer: Use pytorch device: cuda
22-11-06 00:38:27 - INFO - __main__: SBert model paraphrase-multilingual-MiniLM-L12-v2 is loaded.
22-11-06 00:38:29 - INFO - __main__: Num of SBert features: 384
22-11-06 00:38:29 - INFO - root: Generating sentence embeddings
22-11-06 00:38:34 - INFO - root: Generated sentence embeddings
22-11-06 00:38:34 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation
22-11-06 00:39:01 - INFO - root: Best param found at split 1: l2reg = 0.0001                 with score 76.35
22-11-06 00:39:29 - INFO - root: Best param found at split 2: l2reg = 0.01                 with score 77.11
22-11-06 00:39:58 - INFO - root: Best param found at split 3: l2reg = 1e-05                 with score 76.72
22-11-06 00:40:28 - INFO - root: Best param found at split 4: l2reg = 0.01                 with score 78.02
22-11-06 00:40:54 - INFO - root: Best param found at split 5: l2reg = 1e-05                 with score 75.36
22-11-06 00:40:56 - INFO - root: Generating sentence embeddings
22-11-06 00:40:57 - INFO - root: Generated sentence embeddings
22-11-06 00:40:57 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation
22-11-06 00:41:07 - INFO - root: Best param found at split 1: l2reg = 1e-05                 with score 88.18
22-11-06 00:41:17 - INFO - root: Best param found at split 2: l2reg = 0.001                 with score 88.84
22-11-06 00:41:27 - INFO - root: Best param found at split 3: l2reg = 0.01                 with score 88.21
22-11-06 00:41:37 - INFO - root: Best param found at split 4: l2reg = 0.01                 with score 88.61
22-11-06 00:41:47 - INFO - root: Best param found at split 5: l2reg = 1e-05                 with score 88.18
22-11-06 00:41:48 - INFO - root: Generating sentence embeddings
22-11-06 00:41:52 - INFO - root: Generated sentence embeddings
22-11-06 00:41:52 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation
22-11-06 00:42:16 - INFO - root: Best param found at split 1: l2reg = 0.001                 with score 91.21
22-11-06 00:42:45 - INFO - root: Best param found at split 2: l2reg = 1e-05                 with score 92.05
22-11-06 00:43:13 - INFO - root: Best param found at split 3: l2reg = 1e-05                 with score 91.6
22-11-06 00:43:37 - INFO - root: Best param found at split 4: l2reg = 0.01                 with score 91.31
22-11-06 00:44:04 - INFO - root: Best param found at split 5: l2reg = 0.001                 with score 91.38
22-11-06 00:44:06 - INFO - root: Generating sentence embeddings
22-11-06 00:44:09 - INFO - root: Generated sentence embeddings
22-11-06 00:44:09 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation
22-11-06 00:44:37 - INFO - root: Best param found at split 1: l2reg = 0.001                 with score 88.67
22-11-06 00:45:05 - INFO - root: Best param found at split 2: l2reg = 0.0001                 with score 89.07
22-11-06 00:45:34 - INFO - root: Best param found at split 3: l2reg = 0.01                 with score 88.74
22-11-06 00:46:02 - INFO - root: Best param found at split 4: l2reg = 1e-05                 with score 88.87
22-11-06 00:46:30 - INFO - root: Best param found at split 5: l2reg = 1e-05                 with score 88.77
22-11-06 00:46:31 - INFO - root: Computing embedding for train
22-11-06 00:46:35 - INFO - root: Computed train embeddings
22-11-06 00:46:35 - INFO - root: Computing embedding for dev
22-11-06 00:46:35 - INFO - root: Computed dev embeddings
22-11-06 00:46:35 - INFO - root: Computing embedding for test
22-11-06 00:46:36 - INFO - root: Computed test embeddings
22-11-06 00:46:36 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with standard validation..
22-11-06 00:46:42 - INFO - root: [('reg:1e-05', 41.87), ('reg:0.0001', 41.51), ('reg:0.001', 40.69), ('reg:0.01', 38.33)]
22-11-06 00:46:42 - INFO - root: Validation : best param found is reg = 1e-05 with score             41.87
22-11-06 00:46:42 - INFO - root: Evaluating...
22-11-06 00:46:44 - INFO - root: ***** Transfer task : TREC *****


22-11-06 00:46:46 - INFO - root: Computed train embeddings
22-11-06 00:46:46 - INFO - root: Computed test embeddings
22-11-06 00:46:46 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with 5-fold cross-validation
22-11-06 00:47:07 - INFO - root: [('reg:1e-05', 76.41), ('reg:0.0001', 77.35), ('reg:0.001', 77.13), ('reg:0.01', 70.36)]
22-11-06 00:47:07 - INFO - root: Cross-validation : best param found is reg = 0.0001             with score 77.35
22-11-06 00:47:07 - INFO - root: Evaluating...
22-11-06 00:47:09 - INFO - root: ***** Transfer task : MRPC *****


22-11-06 00:47:09 - INFO - root: Computing embedding for train
22-11-06 00:47:12 - INFO - root: Computed train embeddings
22-11-06 00:47:12 - INFO - root: Computing embedding for test
22-11-06 00:47:14 - INFO - root: Computed test embeddings
22-11-06 00:47:14 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with 5-fold cross-validation
22-11-06 00:47:26 - INFO - root: [('reg:1e-05', 73.33), ('reg:0.0001', 72.94), ('reg:0.001', 73.87), ('reg:0.01', 73.11)]
22-11-06 00:47:26 - INFO - root: Cross-validation : best param found is reg = 0.001             with score 73.87
22-11-06 00:47:26 - INFO - root: Evaluating...
22-11-18 17:36:00 - INFO - sentence_transformers.SentenceTransformer: Load pretrained SentenceTransformer: paraphrase-multilingual-MiniLM-L12-v2
22-11-18 17:36:01 - INFO - sentence_transformers.SentenceTransformer: Use pytorch device: cuda
22-11-18 17:36:01 - INFO - __main__: SBert model paraphrase-multilingual-MiniLM-L12-v2 is loaded.
22-11-18 17:36:03 - INFO - __main__: Num of SBert features: 384
