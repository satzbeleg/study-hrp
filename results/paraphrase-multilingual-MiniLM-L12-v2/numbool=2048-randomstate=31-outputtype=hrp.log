22-11-06 07:11:42 - INFO - sentence_transformers.SentenceTransformer: Load pretrained SentenceTransformer: paraphrase-multilingual-MiniLM-L12-v2
22-11-06 07:11:43 - INFO - sentence_transformers.SentenceTransformer: Use pytorch device: cuda
22-11-06 07:11:43 - INFO - __main__: SBert model paraphrase-multilingual-MiniLM-L12-v2 is loaded.
22-11-06 07:11:45 - INFO - __main__: Num of SBert features: 384
22-11-06 07:11:46 - INFO - root: Generating sentence embeddings
22-11-06 07:11:51 - INFO - root: Generated sentence embeddings
22-11-06 07:11:51 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation
22-11-06 07:12:19 - INFO - root: Best param found at split 1: l2reg = 0.001                 with score 78.0
22-11-06 07:12:49 - INFO - root: Best param found at split 2: l2reg = 0.0001                 with score 78.05
22-11-06 07:13:18 - INFO - root: Best param found at split 3: l2reg = 0.01                 with score 78.24
22-11-06 07:13:47 - INFO - root: Best param found at split 4: l2reg = 0.01                 with score 78.18
22-11-06 07:14:18 - INFO - root: Best param found at split 5: l2reg = 0.01                 with score 77.26
22-11-06 07:14:20 - INFO - root: Generating sentence embeddings
22-11-06 07:14:22 - INFO - root: Generated sentence embeddings
22-11-06 07:14:22 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation
22-11-06 07:14:31 - INFO - root: Best param found at split 1: l2reg = 0.01                 with score 88.44
22-11-06 07:14:40 - INFO - root: Best param found at split 2: l2reg = 1e-05                 with score 88.91
22-11-06 07:14:50 - INFO - root: Best param found at split 3: l2reg = 1e-05                 with score 87.78
22-11-06 07:15:00 - INFO - root: Best param found at split 4: l2reg = 0.01                 with score 88.11
22-11-06 07:15:10 - INFO - root: Best param found at split 5: l2reg = 1e-05                 with score 87.65
22-11-06 07:15:10 - INFO - root: Generating sentence embeddings
22-11-06 07:15:15 - INFO - root: Generated sentence embeddings
22-11-06 07:15:15 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation
22-11-06 07:15:34 - INFO - root: Best param found at split 1: l2reg = 0.001                 with score 91.51
22-11-06 07:16:00 - INFO - root: Best param found at split 2: l2reg = 0.0001                 with score 91.99
22-11-06 07:16:25 - INFO - root: Best param found at split 3: l2reg = 0.0001                 with score 91.89
22-11-06 07:16:51 - INFO - root: Best param found at split 4: l2reg = 0.001                 with score 91.41
22-11-06 07:17:17 - INFO - root: Best param found at split 5: l2reg = 0.01                 with score 91.49
22-11-06 07:17:19 - INFO - root: Generating sentence embeddings
22-11-06 07:17:22 - INFO - root: Generated sentence embeddings
22-11-06 07:17:22 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation
22-11-06 07:17:51 - INFO - root: Best param found at split 1: l2reg = 0.01                 with score 89.2
22-11-06 07:18:17 - INFO - root: Best param found at split 2: l2reg = 0.01                 with score 88.7
22-11-06 07:18:46 - INFO - root: Best param found at split 3: l2reg = 0.01                 with score 89.04
22-11-06 07:19:06 - INFO - root: Best param found at split 4: l2reg = 0.001                 with score 88.84
22-11-06 07:19:30 - INFO - root: Best param found at split 5: l2reg = 0.001                 with score 88.6
22-11-06 07:19:32 - INFO - root: Computing embedding for train
22-11-06 07:19:35 - INFO - root: Computed train embeddings
22-11-06 07:19:35 - INFO - root: Computing embedding for dev
22-11-06 07:19:36 - INFO - root: Computed dev embeddings
22-11-06 07:19:36 - INFO - root: Computing embedding for test
22-11-06 07:19:37 - INFO - root: Computed test embeddings
22-11-06 07:19:37 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with standard validation..
22-11-06 07:19:43 - INFO - root: [('reg:1e-05', 43.14), ('reg:0.0001', 42.23), ('reg:0.001', 42.42), ('reg:0.01', 40.6)]
22-11-06 07:19:43 - INFO - root: Validation : best param found is reg = 1e-05 with score             43.14
22-11-06 07:19:43 - INFO - root: Evaluating...
22-11-06 07:19:45 - INFO - root: ***** Transfer task : TREC *****


22-11-06 07:19:47 - INFO - root: Computed train embeddings
22-11-06 07:19:47 - INFO - root: Computed test embeddings
22-11-06 07:19:47 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with 5-fold cross-validation
22-11-06 07:20:06 - INFO - root: [('reg:1e-05', 77.0), ('reg:0.0001', 78.26), ('reg:0.001', 74.45), ('reg:0.01', 78.19)]
22-11-06 07:20:06 - INFO - root: Cross-validation : best param found is reg = 0.0001             with score 78.26
22-11-06 07:20:06 - INFO - root: Evaluating...
22-11-06 07:20:07 - INFO - root: ***** Transfer task : MRPC *****


22-11-06 07:20:07 - INFO - root: Computing embedding for train
22-11-06 07:20:10 - INFO - root: Computed train embeddings
22-11-06 07:20:10 - INFO - root: Computing embedding for test
22-11-06 07:20:12 - INFO - root: Computed test embeddings
22-11-06 07:20:12 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with 5-fold cross-validation
22-11-06 07:20:25 - INFO - root: [('reg:1e-05', 73.55), ('reg:0.0001', 73.77), ('reg:0.001', 72.6), ('reg:0.01', 71.84)]
22-11-06 07:20:25 - INFO - root: Cross-validation : best param found is reg = 0.0001             with score 73.77
22-11-06 07:20:25 - INFO - root: Evaluating...
22-11-18 20:11:55 - INFO - sentence_transformers.SentenceTransformer: Load pretrained SentenceTransformer: paraphrase-multilingual-MiniLM-L12-v2
22-11-18 20:11:57 - INFO - sentence_transformers.SentenceTransformer: Use pytorch device: cuda
22-11-18 20:11:57 - INFO - __main__: SBert model paraphrase-multilingual-MiniLM-L12-v2 is loaded.
22-11-18 20:11:58 - INFO - __main__: Num of SBert features: 384
