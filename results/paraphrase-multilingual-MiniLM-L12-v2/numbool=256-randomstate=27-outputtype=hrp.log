22-11-05 02:13:59 - INFO - sentence_transformers.SentenceTransformer: Load pretrained SentenceTransformer: paraphrase-multilingual-MiniLM-L12-v2
22-11-05 02:14:01 - INFO - sentence_transformers.SentenceTransformer: Use pytorch device: cuda
22-11-05 02:14:01 - INFO - __main__: SBert model paraphrase-multilingual-MiniLM-L12-v2 is loaded.
22-11-05 02:14:03 - INFO - __main__: Num of SBert features: 384
22-11-05 02:14:04 - INFO - root: Generating sentence embeddings
22-11-05 02:14:08 - INFO - root: Generated sentence embeddings
22-11-05 02:14:08 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation
22-11-05 02:14:32 - INFO - root: Best param found at split 1: l2reg = 0.01                 with score 76.63
22-11-05 02:15:01 - INFO - root: Best param found at split 2: l2reg = 1e-05                 with score 76.03
22-11-05 02:15:31 - INFO - root: Best param found at split 3: l2reg = 0.01                 with score 76.35
22-11-05 02:15:58 - INFO - root: Best param found at split 4: l2reg = 0.01                 with score 76.14
22-11-05 02:16:28 - INFO - root: Best param found at split 5: l2reg = 0.001                 with score 76.37
22-11-05 02:16:29 - INFO - root: Generating sentence embeddings
22-11-05 02:16:31 - INFO - root: Generated sentence embeddings
22-11-05 02:16:31 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation
22-11-05 02:16:40 - INFO - root: Best param found at split 1: l2reg = 0.001                 with score 86.52
22-11-05 02:16:49 - INFO - root: Best param found at split 2: l2reg = 0.001                 with score 86.46
22-11-05 02:16:59 - INFO - root: Best param found at split 3: l2reg = 0.01                 with score 86.42
22-11-05 02:17:08 - INFO - root: Best param found at split 4: l2reg = 1e-05                 with score 86.59
22-11-05 02:17:17 - INFO - root: Best param found at split 5: l2reg = 0.001                 with score 85.33
22-11-05 02:17:18 - INFO - root: Generating sentence embeddings
22-11-05 02:17:22 - INFO - root: Generated sentence embeddings
22-11-05 02:17:22 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation
22-11-05 02:17:48 - INFO - root: Best param found at split 1: l2reg = 0.01                 with score 88.65
22-11-05 02:18:15 - INFO - root: Best param found at split 2: l2reg = 0.001                 with score 88.9
22-11-05 02:18:40 - INFO - root: Best param found at split 3: l2reg = 0.001                 with score 88.99
22-11-05 02:19:06 - INFO - root: Best param found at split 4: l2reg = 0.001                 with score 88.65
22-11-05 02:19:33 - INFO - root: Best param found at split 5: l2reg = 0.01                 with score 88.65
22-11-05 02:19:35 - INFO - root: Generating sentence embeddings
22-11-05 02:19:38 - INFO - root: Generated sentence embeddings
22-11-05 02:19:38 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation
22-11-05 02:20:05 - INFO - root: Best param found at split 1: l2reg = 0.001                 with score 87.4
22-11-05 02:20:33 - INFO - root: Best param found at split 2: l2reg = 1e-05                 with score 87.0
22-11-05 02:21:01 - INFO - root: Best param found at split 3: l2reg = 0.01                 with score 87.48
22-11-05 02:21:32 - INFO - root: Best param found at split 4: l2reg = 0.0001                 with score 87.38
22-11-05 02:21:58 - INFO - root: Best param found at split 5: l2reg = 0.01                 with score 87.79
22-11-05 02:22:00 - INFO - root: Computing embedding for train
22-11-05 02:22:03 - INFO - root: Computed train embeddings
22-11-05 02:22:03 - INFO - root: Computing embedding for dev
22-11-05 02:22:03 - INFO - root: Computed dev embeddings
22-11-05 02:22:03 - INFO - root: Computing embedding for test
22-11-05 02:22:04 - INFO - root: Computed test embeddings
22-11-05 02:22:04 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with standard validation..
22-11-05 02:22:11 - INFO - root: [('reg:1e-05', 42.78), ('reg:0.0001', 42.87), ('reg:0.001', 42.69), ('reg:0.01', 42.96)]
22-11-05 02:22:11 - INFO - root: Validation : best param found is reg = 0.01 with score             42.96
22-11-05 02:22:11 - INFO - root: Evaluating...
22-11-05 02:22:13 - INFO - root: ***** Transfer task : TREC *****


22-11-05 02:22:15 - INFO - root: Computed train embeddings
22-11-05 02:22:15 - INFO - root: Computed test embeddings
22-11-05 02:22:15 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with 5-fold cross-validation
22-11-05 02:22:33 - INFO - root: [('reg:1e-05', 70.19), ('reg:0.0001', 70.1), ('reg:0.001', 70.19), ('reg:0.01', 69.0)]
22-11-05 02:22:33 - INFO - root: Cross-validation : best param found is reg = 1e-05             with score 70.19
22-11-05 02:22:33 - INFO - root: Evaluating...
22-11-05 02:22:34 - INFO - root: ***** Transfer task : MRPC *****


22-11-05 02:22:34 - INFO - root: Computing embedding for train
22-11-05 02:22:37 - INFO - root: Computed train embeddings
22-11-05 02:22:37 - INFO - root: Computing embedding for test
22-11-05 02:22:39 - INFO - root: Computed test embeddings
22-11-05 02:22:39 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with 5-fold cross-validation
22-11-05 02:22:51 - INFO - root: [('reg:1e-05', 72.72), ('reg:0.0001', 72.79), ('reg:0.001', 72.64), ('reg:0.01', 72.45)]
22-11-05 02:22:51 - INFO - root: Cross-validation : best param found is reg = 0.0001             with score 72.79
22-11-05 02:22:51 - INFO - root: Evaluating...
22-11-18 09:10:21 - INFO - sentence_transformers.SentenceTransformer: Load pretrained SentenceTransformer: paraphrase-multilingual-MiniLM-L12-v2
22-11-18 09:10:22 - INFO - sentence_transformers.SentenceTransformer: Use pytorch device: cuda
22-11-18 09:10:22 - INFO - __main__: SBert model paraphrase-multilingual-MiniLM-L12-v2 is loaded.
22-11-18 09:10:24 - INFO - __main__: Num of SBert features: 384
