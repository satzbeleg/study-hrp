22-11-05 00:27:17 - INFO - sentence_transformers.SentenceTransformer: Load pretrained SentenceTransformer: paraphrase-multilingual-MiniLM-L12-v2
22-11-05 00:27:18 - INFO - sentence_transformers.SentenceTransformer: Use pytorch device: cuda
22-11-05 00:27:18 - INFO - __main__: SBert model paraphrase-multilingual-MiniLM-L12-v2 is loaded.
22-11-05 00:27:20 - INFO - __main__: Num of SBert features: 384
22-11-05 00:27:21 - INFO - root: Generating sentence embeddings
22-11-05 00:27:26 - INFO - root: Generated sentence embeddings
22-11-05 00:27:26 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation
22-11-05 00:27:52 - INFO - root: Best param found at split 1: l2reg = 0.01                 with score 76.43
22-11-05 00:28:22 - INFO - root: Best param found at split 2: l2reg = 0.01                 with score 75.61
22-11-05 00:28:49 - INFO - root: Best param found at split 3: l2reg = 0.01                 with score 75.58
22-11-05 00:29:20 - INFO - root: Best param found at split 4: l2reg = 0.01                 with score 75.55
22-11-05 00:29:49 - INFO - root: Best param found at split 5: l2reg = 0.01                 with score 76.48
22-11-05 00:29:50 - INFO - root: Generating sentence embeddings
22-11-05 00:29:52 - INFO - root: Generated sentence embeddings
22-11-05 00:29:52 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation
22-11-05 00:30:00 - INFO - root: Best param found at split 1: l2reg = 0.01                 with score 88.11
22-11-05 00:30:09 - INFO - root: Best param found at split 2: l2reg = 0.01                 with score 87.88
22-11-05 00:30:19 - INFO - root: Best param found at split 3: l2reg = 0.001                 with score 87.42
22-11-05 00:30:28 - INFO - root: Best param found at split 4: l2reg = 1e-05                 with score 88.38
22-11-05 00:30:38 - INFO - root: Best param found at split 5: l2reg = 1e-05                 with score 88.01
22-11-05 00:30:38 - INFO - root: Generating sentence embeddings
22-11-05 00:30:43 - INFO - root: Generated sentence embeddings
22-11-05 00:30:43 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation
22-11-05 00:31:09 - INFO - root: Best param found at split 1: l2reg = 0.01                 with score 88.26
22-11-05 00:31:36 - INFO - root: Best param found at split 2: l2reg = 1e-05                 with score 88.21
22-11-05 00:32:03 - INFO - root: Best param found at split 3: l2reg = 0.001                 with score 88.26
22-11-05 00:32:29 - INFO - root: Best param found at split 4: l2reg = 0.01                 with score 87.74
22-11-05 00:32:56 - INFO - root: Best param found at split 5: l2reg = 0.0001                 with score 87.94
22-11-05 00:32:58 - INFO - root: Generating sentence embeddings
22-11-05 00:33:01 - INFO - root: Generated sentence embeddings
22-11-05 00:33:01 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation
22-11-05 00:33:28 - INFO - root: Best param found at split 1: l2reg = 1e-05                 with score 86.46
22-11-05 00:33:58 - INFO - root: Best param found at split 2: l2reg = 0.001                 with score 86.64
22-11-05 00:34:31 - INFO - root: Best param found at split 3: l2reg = 1e-05                 with score 86.86
22-11-05 00:34:58 - INFO - root: Best param found at split 4: l2reg = 0.01                 with score 86.91
22-11-05 00:35:31 - INFO - root: Best param found at split 5: l2reg = 0.001                 with score 86.99
22-11-05 00:35:33 - INFO - root: Computing embedding for train
22-11-05 00:35:37 - INFO - root: Computed train embeddings
22-11-05 00:35:37 - INFO - root: Computing embedding for dev
22-11-05 00:35:37 - INFO - root: Computed dev embeddings
22-11-05 00:35:37 - INFO - root: Computing embedding for test
22-11-05 00:35:38 - INFO - root: Computed test embeddings
22-11-05 00:35:38 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with standard validation..
22-11-05 00:35:45 - INFO - root: [('reg:1e-05', 39.87), ('reg:0.0001', 39.87), ('reg:0.001', 39.69), ('reg:0.01', 39.87)]
22-11-05 00:35:45 - INFO - root: Validation : best param found is reg = 1e-05 with score             39.87
22-11-05 00:35:45 - INFO - root: Evaluating...
22-11-05 00:35:47 - INFO - root: ***** Transfer task : TREC *****


22-11-05 00:35:48 - INFO - root: Computed train embeddings
22-11-05 00:35:49 - INFO - root: Computed test embeddings
22-11-05 00:35:49 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with 5-fold cross-validation
22-11-05 00:36:05 - INFO - root: [('reg:1e-05', 69.61), ('reg:0.0001', 69.57), ('reg:0.001', 69.48), ('reg:0.01', 68.1)]
22-11-05 00:36:05 - INFO - root: Cross-validation : best param found is reg = 1e-05             with score 69.61
22-11-05 00:36:05 - INFO - root: Evaluating...
22-11-05 00:36:06 - INFO - root: ***** Transfer task : MRPC *****


22-11-05 00:36:06 - INFO - root: Computing embedding for train
22-11-05 00:36:10 - INFO - root: Computed train embeddings
22-11-05 00:36:10 - INFO - root: Computing embedding for test
22-11-05 00:36:11 - INFO - root: Computed test embeddings
22-11-05 00:36:11 - INFO - root: Training pytorch-MLP-nhid0-rmsprop-bs128 with 5-fold cross-validation
22-11-05 00:36:25 - INFO - root: [('reg:1e-05', 71.74), ('reg:0.0001', 71.74), ('reg:0.001', 71.61), ('reg:0.01', 71.69)]
22-11-05 00:36:25 - INFO - root: Cross-validation : best param found is reg = 1e-05             with score 71.74
22-11-05 00:36:25 - INFO - root: Evaluating...
22-11-18 08:29:19 - INFO - sentence_transformers.SentenceTransformer: Load pretrained SentenceTransformer: paraphrase-multilingual-MiniLM-L12-v2
22-11-18 08:29:20 - INFO - sentence_transformers.SentenceTransformer: Use pytorch device: cuda
22-11-18 08:29:20 - INFO - __main__: SBert model paraphrase-multilingual-MiniLM-L12-v2 is loaded.
22-11-18 08:29:22 - INFO - __main__: Num of SBert features: 384
